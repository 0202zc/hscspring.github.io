<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <meta name="description" content="Yam | AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习" />
  

  
  
  
  
  
  <title>Yam</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Yam | AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
<meta property="og:type" content="website">
<meta property="og:title" content="Yam">
<meta property="og:url" content="http://www.yam.gift/page/2/index.html">
<meta property="og:site_name" content="Yam">
<meta property="og:description" content="Yam | AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yam">
<meta name="twitter:description" content="Yam | AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="home blog custom-background custom-font-enabled single-author">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="Yam" rel="home">Yam</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">Feeling, Coding, Thinking</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives/">Archives</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about/">About</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="http://github.com/hscspring">Projects</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main">
  
    <article id="post-NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing" class="post-NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/03/29/NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing/">自然语言计算机形式分析的理论与方法笔记(Ch15)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/03/29/NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing/" data-id="cjvadb63h008iqscc03m39p0a" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十五章：语音自动处理的形式模型"><a href="#第十五章：语音自动处理的形式模型" class="headerlink" title="第十五章：语音自动处理的形式模型"></a>第十五章：语音自动处理的形式模型</h1><p>语音自动处理主要包括：自动语音识别(ASR) 和文本-语音转换(TTS)。</p>
        
          <p class="article-more-link">
            <a href="/2019/03/29/NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/03/29/NLPFA/2019-03-29-Ch15-Formal-Model-of-Automatic-Speech-Processing/">
    <time datetime="2019-03-29T03:32:00.000Z" class="entry-date">
        2019-03-29
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Automatic-Speech-Processing/">Automatic Speech Processing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-03-22-Ch14-HMM" class="post-NLPFA/2019-03-22-Ch14-HMM post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/03/22/NLPFA/2019-03-22-Ch14-HMM/">自然语言计算机形式分析的理论与方法笔记(Ch14)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/03/22/NLPFA/2019-03-22-Ch14-HMM/" data-id="cjvadb61v004xqscc9kqos2pg" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十四章：隐-Markov-模型"><a href="#第十四章：隐-Markov-模型" class="headerlink" title="第十四章：隐 Markov 模型"></a>第十四章：隐 Markov 模型</h1><h2 id="HMM-概述"><a href="#HMM-概述" class="headerlink" title="HMM 概述"></a>HMM 概述</h2><p>Markov 链也就是加权自动机。HMM 增加了要求：</p>
<ul>
<li>HMM 有一个观察符号的集合 O，这个集合中的符号不是从状态集合 Q 中的字母抽取的</li>
<li>HMM 中观察似然度函数 B 的值不只限于 1 或 0，概率 bi(ot) 可以取 0-1 之间的任何值</li>
</ul>
<p>HMM 要求的参数如下：</p>
<ul>
<li>状态序列：Q = (q1, q2, …, qn)</li>
<li>观察序列：O = (o1, o2, …, on)</li>
<li>转换概率：A = (a01, a02, …, ann)</li>
<li>观察似然度：B = bi(ot)，表示从状态 i 生成观察值 ot 的概率</li>
<li>初始状态概率分布：π，πi 是 HMM 在状态 i 开始时的概率</li>
<li>接收状态：合法的接收状态集合</li>
</ul>
<p>需要求解的是 A B π，因此一般使用 λ = {A, B, π} 来定义一个 HMM 模型，模型对外表现出来的是观察序列，状态序列不能直接观察到，被称为 “隐变量”。</p>
<p>三个基本问题：</p>
<ul>
<li>评估问题：给定观察序列 O 和模型 λ，如何计算由该模型产生该观察序列的概率 P(O|λ)</li>
<li>解码问题：给定观察序列 O 和模型 λ，如何获取在某种意义下最优的状态序列 Q，一般使用 Viterbi 算法</li>
<li>训练问题：如何选择或调整模型参数 λ，使得在该模型下产生观察序列 O 的概率 P(O|λ) 最大</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2019/03/22/NLPFA/2019-03-22-Ch14-HMM/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/03/22/NLPFA/2019-03-22-Ch14-HMM/">
    <time datetime="2019-03-22T03:32:00.000Z" class="entry-date">
        2019-03-22
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HMM/">HMM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Markov/">Markov</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing" class="post-NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/03/15/NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing/">自然语言计算机形式分析的理论与方法笔记(Ch13)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/03/15/NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing/" data-id="cjvadb61r004qqscc8ocpbc1w" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十三章：N-元语法和数据平滑"><a href="#第十三章：N-元语法和数据平滑" class="headerlink" title="第十三章：N 元语法和数据平滑"></a>第十三章：N 元语法和数据平滑</h1><h2 id="N-元语法"><a href="#N-元语法" class="headerlink" title="N 元语法"></a>N 元语法</h2><p>N 元语法模型利用前面 N-1 个单词来预测下一个词。一些特殊情况：标点、大小写、屈折变化等。</p>
<p>一个单词的概率只依赖于它前面一个单词的这种假设叫作 Markov 假设，这样的模型叫 Bi-gram，即二元语法模型，也叫一阶 Markov 模型。</p>
<p>N 元语法模型可以使用训练语料库 “归一化” 得到。</p>
<script type="math/tex; mode=display">p(w_n|w_{n-1}) = \frac {C(w_{n-1}w_n)}{\sum_w C(w_{n-1}w)}​</script><p>以 <script type="math/tex">w_{n-1}</script> 开头的二元语法计数必定等于 <script type="math/tex">w_{n-1}</script> 这个单词的计数，于是：</p>
<script type="math/tex; mode=display">p(w_n|w_{n-1}) = \frac {C(w_{n-1}w_n)}{C(w_{n-1})}</script><p>一般化 N 元语法的参数估计：</p>
<script type="math/tex; mode=display">p(w_n|w_{n-N+1}^{n-1}) = \frac {C(w_{n-N+1}^{n-1}w_n)}{C(w_{n-N+1}^{n-1})}</script><p>两个重要事实：</p>
<ul>
<li>N 增加时，精确度相应增加，同时生成句子的局限性增加（可选的下个词减少）</li>
<li>严重依赖于语料库</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2019/03/15/NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/03/15/NLPFA/2019-03-15-Ch13-Ngram-and-Smoothing/">
    <time datetime="2019-03-15T03:32:00.000Z" class="entry-date">
        2019-03-15
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Ngram/">Ngram</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Smoothing/">Smoothing</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming" class="post-NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/03/11/NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming/">自然语言计算机形式分析的理论与方法笔记(Ch12)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/03/11/NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming/" data-id="cjvadb61t004uqscciopqtecx" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十二章：Bayes-公式与动态规划算法"><a href="#第十二章：Bayes-公式与动态规划算法" class="headerlink" title="第十二章：Bayes 公式与动态规划算法"></a>第十二章：Bayes 公式与动态规划算法</h1><h2 id="拼写错误的检查与更正"><a href="#拼写错误的检查与更正" class="headerlink" title="拼写错误的检查与更正"></a>拼写错误的检查与更正</h2><p>1992 年，Kukich 把这个领域分解为三大问题：</p>
<ul>
<li>非词错误检查</li>
<li>孤立词错误更正</li>
<li>依赖于上下文的错误检查和更正<ul>
<li>打字操作时的错误：插入、脱落、改变位置等</li>
<li>书写错误地拼写同音词和准同音词</li>
</ul>
</li>
</ul>
<p>1964 年 Damerau 发现 80% 的错误由 “单个错误” 引起的：</p>
<ul>
<li>插入：the→ther</li>
<li>脱落：the→th</li>
<li>替代：the→thw</li>
<li>换位：the→hte</li>
</ul>
<p>Kukich 把打字错误分为两类：</p>
<ul>
<li>打字操作错误：一般与键盘有关</li>
<li>认知错误：不知道如何拼写</li>
</ul>
<p>OCR 错误一般分为五类：替代、多重替代、空白脱落、空白插入和识别失败。</p>
        
          <p class="article-more-link">
            <a href="/2019/03/11/NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/03/11/NLPFA/2019-03-11-Ch12-Bayes-and-Dynamic-Programming/">
    <time datetime="2019-03-11T03:32:00.000Z" class="entry-date">
        2019-03-11
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Backward/">Backward</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayes/">Bayes</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/FSM/">FSM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Forward/">Forward</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Minimum-Edit-Distance/">Minimum Edit Distance</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Spell-Check/">Spell Check</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Viterbi/">Viterbi</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-03-01-Ch11-Probabilistic-Grammar" class="post-NLPFA/2019-03-01-Ch11-Probabilistic-Grammar post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/03/01/NLPFA/2019-03-01-Ch11-Probabilistic-Grammar/">自然语言计算机形式分析的理论与方法笔记(Ch11)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/03/01/NLPFA/2019-03-01-Ch11-Probabilistic-Grammar/" data-id="cjvadb60s003jqsccnjhykgf0" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十一章：概率语法"><a href="#第十一章：概率语法" class="headerlink" title="第十一章：概率语法"></a>第十一章：概率语法</h1><p>基于规则的句法剖析主要使用 Chomsky 的上下文无关语法。之前的自顶向下、自底向上、左角、CYK、Earley、线图分析法等都对歧义无能为力，于是有了新的改进：一方面是给上下文无关语法的规则加上概率，另一方面是除了加上概率外，还考虑规则的中心词对于规则概率的影响。这些称为 “概率语法”。</p>
        
          <p class="article-more-link">
            <a href="/2019/03/01/NLPFA/2019-03-01-Ch11-Probabilistic-Grammar/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/03/01/NLPFA/2019-03-01-Ch11-Probabilistic-Grammar/">
    <time datetime="2019-03-01T03:32:00.000Z" class="entry-date">
        2019-03-01
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Probabilistic-Grammar/">Probabilistic Grammar</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing" class="post-NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/02/27/NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing/">自然语言计算机形式分析的理论与方法笔记(Ch10)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/02/27/NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing/" data-id="cjvadb63f008gqsccrav89ytu" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第十章：语用自动处理的形式模型"><a href="#第十章：语用自动处理的形式模型" class="headerlink" title="第十章：语用自动处理的形式模型"></a>第十章：语用自动处理的形式模型</h1><p>语用学是对语言与使用环境之间关系的研究。使用环境包括像人和物这样的本体，也包括话语的上下文。研究主要涉及修辞结构理论、文本连贯、言语行为理论和会话智能代理等方面。</p>
        
          <p class="article-more-link">
            <a href="/2019/02/27/NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/02/27/NLPFA/2019-02-27-Ch10-Formal-Model-of-Pragmatic-Automatic-Processing/">
    <time datetime="2019-02-27T03:32:00.000Z" class="entry-date">
        2019-02-27
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pragmatic-Automatic-Processing/">Pragmatic Automatic Processing</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-02-21-Ch09-System-Function-Syntax" class="post-NLPFA/2019-02-21-Ch09-System-Function-Syntax post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/02/21/NLPFA/2019-02-21-Ch09-System-Function-Syntax/">自然语言计算机形式分析的理论与方法笔记(Ch09)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/02/21/NLPFA/2019-02-21-Ch09-System-Function-Syntax/" data-id="cjvadb62s007cqscc016oafm3" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第九章：系统功能语法"><a href="#第九章：系统功能语法" class="headerlink" title="第九章：系统功能语法"></a>第九章：系统功能语法</h1><h2 id="系统功能语法的基本概念"><a href="#系统功能语法的基本概念" class="headerlink" title="系统功能语法的基本概念"></a>系统功能语法的基本概念</h2><p>英国语言学家 M. A. K. Halliday 提出，他继承并发扬了他的老师 Firth 为代表的伦敦语言学派的功能主义理论。</p>
        
          <p class="article-more-link">
            <a href="/2019/02/21/NLPFA/2019-02-21-Ch09-System-Function-Syntax/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/02/21/NLPFA/2019-02-21-Ch09-System-Function-Syntax/">
    <time datetime="2019-02-21T03:32:00.000Z" class="entry-date">
        2019-02-21
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Function-Syntax/">Function Syntax</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing" class="post-NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/02/15/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/">自然语言计算机形式分析的理论与方法笔记(Ch08)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/02/15/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/" data-id="cjvadb64b0097qscczsdg8fw2" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第八章：语义自动处理的形式模型"><a href="#第八章：语义自动处理的形式模型" class="headerlink" title="第八章：语义自动处理的形式模型"></a>第八章：语义自动处理的形式模型</h1><p>关于语义与语法分析的关系，有两种方式：先句法后语义和句法语义一体化。</p>
        
          <p class="article-more-link">
            <a href="/2019/02/15/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/02/15/NLPFA/2019-02-15-Ch08-Formal-Model-of-Semantic-Automatic-Processing/">
    <time datetime="2019-02-15T03:32:00.000Z" class="entry-date">
        2019-02-15
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Semantic-Automatic-Processing/">Semantic Automatic Processing</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism" class="post-NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/01/31/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/">自然语言计算机形式分析的理论与方法笔记(Ch07)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/01/31/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/" data-id="cjvadb63d008dqsccb614j1px" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第七章：基于词汇主义的形式模型"><a href="#第七章：基于词汇主义的形式模型" class="headerlink" title="第七章：基于词汇主义的形式模型"></a>第七章：基于词汇主义的形式模型</h1><h2 id="Gross-的词汇语法"><a href="#Gross-的词汇语法" class="headerlink" title="Gross 的词汇语法"></a>Gross 的词汇语法</h2><p>1975 年，Gross 首次提出 “词汇语法” 的理论，1979 年进一步完善了理论，是一种基于词汇主义的形式化语言理论。词汇语法的理论基础是结构主义语言学。</p>
<ul>
<li><p>坚持索绪尔的纯语言学立场，主张 “语言学唯一的、真正的对象是就语言并为语言而研究的语言”，把语言定义为一种特殊的、带有自然现象许多特点的社会现象，主张从语言的内在结构去研究，即把语言作为音义结合的符号系统来研究，把一切非语言的因素严格限制在一个能把握得了的范围之内。</p>
</li>
<li><p>坚持结构主义方法论原则。即语言是一个结构系统，应当注重各个成分之间关系的探索，重视共时的研究，强调形式的分析和描写。</p>
</li>
<li><p>坚持实证主义的变换方法。</p>
</li>
<li><p>中心思想是词汇及语法，对二者的互动关系探求应当系统地进行。</p>
</li>
<li><p>在理论和实践的关系上，坚持方法的选择必须以应用价值为先导，反对以假设为前提、忽视应用的做法。</p>
</li>
<li><p>主张句法独立，坚持在句法描写中摈弃语义上的先验模式，使语义的描写处于最低量态度，做到 “语义低量”。Gross 坚信，句法可以形式化到相当的应用程度，而语义不可能独立于句法而达到形式化，他不排斥语义，但是主张语义描写的最低量。</p>
<blockquote>
<p>如果从形式化角度来说，语义的确不如句法；但句法的出现和发展也是为了表达语义的。</p>
<p>我现在越来越怀疑语言学的这一系列研究方法，肯定有其价值，但到底是不是正确的方向，或者说究竟有没有正确的方向？  </p>
<p>从某种意义上来说，词汇语法有一定道理，尤其是其基于词汇主义的思想，词很有可能比现有研究所表现出来的更加重要。</p>
</blockquote>
</li>
<li><p>相信一切语言理论和方法都受到语言事实的检验。</p>
</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2019/01/31/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/01/31/NLPFA/2019-01-31-Ch07-Formal-Model-Based-on-Lexicalism/">
    <time datetime="2019-01-31T03:32:00.000Z" class="entry-date">
        2019-01-31
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Lexicalism/">Lexicalism</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>





  
    <article id="post-NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar" class="post-NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title">
      <a class="article-title" href="/2019/01/18/NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar/">自然语言计算机形式分析的理论与方法笔记(Ch06)</a>
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://www.yam.gift/2019/01/18/NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar/" data-id="cjvadb61q004nqscceivj7bqh" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="第六章：基于格语法的形式模型"><a href="#第六章：基于格语法的形式模型" class="headerlink" title="第六章：基于格语法的形式模型"></a>第六章：基于格语法的形式模型</h1><h2 id="Fillmore-的格语法"><a href="#Fillmore-的格语法" class="headerlink" title="Fillmore 的格语法"></a>Fillmore 的格语法</h2><p>美国语言学家 C.Fillmore 提出的语法理论。发展的两个阶段：</p>
<ul>
<li>20 世纪 60 年代末到 70 年代初：只用格分析平面做工具，把句子的底层语义表达跟句子描述的情景的特点联系起来，不考虑深层语法关系平面。</li>
<li>20 世纪 70 年代中期以后：增加了深层语法关系平面来解释语义和句法现象。</li>
</ul>
        
          <p class="article-more-link">
            <a href="/2019/01/18/NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar/#more" class="more-link">More <span class="meta-nav">→</span></a>
          </p>
        
      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/01/18/NLPFA/2019-01-18-Ch06-Formal-Model-Based-on-Grid-Grammar/">
    <time datetime="2019-01-18T03:32:00.000Z" class="entry-date">
        2019-01-18
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/">AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Grid-Grammar/">Grid Grammar</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>





  
  
    <nav id="pagination">
      <nav id="page-nav">
        <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
      </nav>
    </nav>
  
</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    <aside id="search" class="widget widget_search"><form role="search" method="get" accept-charset="utf-8" id="searchform" class="searchform" action="//google.com/search">
    <div>
        <input type="text" value="" name="s" id="s" />
        <input type="submit" id="searchsubmit" value="搜索" />
    </div>
</form></aside>
  
    
  <aside class="widget">
    <h3 class="widget-title">Music</h3>
    <div class="widget-content">
      <audio src="http://qnimg.lovevivian.cn/miss.mp3" controls="controls"
             style="width:100%">
        您的浏览器不支持 audio 标签。
      </audio>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feeling/">Feeling</a><span class="category-list-count">33</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a><span class="category-list-count">9</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2019/05/31/SLP/2019-05-31-Neural-Networks-and-Neural-Language-Models/">Neural Networks and Neural Language Models Note (SLP Ch07)</a>
          </li>
        
          <li>
            <a href="/2019/05/16/SLP/2019-05-16-Vector-Semantics/">Vector Semantics Note (SLP Ch06)</a>
          </li>
        
          <li>
            <a href="/2019/05/08/SLP/2019-05-08-Logistic-Regression/">Logistic Regression Note (SLP Ch05)</a>
          </li>
        
          <li>
            <a href="/2019/05/05/SLP/2019-05-05-NaiveBayes-and-Sentiment-Classification/">Naive Bayes and Sentiment Classification Note (SLP Ch04)</a>
          </li>
        
          <li>
            <a href="/2019/04/22/SLP/2019-04-22-RegularExpressions-TextNormalization-EditDistance/">Regular Expressions, Text Normalization, and Edit Distance Note (SLP Ch02)</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tags</h3>
    <div class="widget-content">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/">AI</a><span class="tag-list-count">36</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Automatic-Speech-Processing/">Automatic Speech Processing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Backward/">Backward</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes/">Bayes</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Business/">Business</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Calculus/">Calculus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computational-Linguistics/">Computational Linguistics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Science/">Computer Science</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cosine/">Cosine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cross-Entropy/">Cross Entropy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DB/">DB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNN/">DNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Clearing/">Data Clearing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Science/">Data Science</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Structure/">Data Structure</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/">DeepLearning</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dependence/">Dependence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Diary/">Diary</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Economics/">Economics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Edit-Distance/">Edit Distance</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Embeddings/">Embeddings</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Entropy/">Entropy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Evaluation/">Evaluation</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/F1/">F1</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FDW/">FDW</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/FSM/">FSM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Formal-Analysis/">Formal Analysis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Forward/">Forward</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Function-Syntax/">Function Syntax</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gan/">Gan</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gradient-Descent/">Gradient Descent</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Grid-Grammar/">Grid Grammar</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HMM/">HMM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IE/">IE</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Industry/">Industry</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Information-Extraction/">Information Extraction</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LM/">LM</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Language-Model/">Language Model</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lexical-Semantics/">Lexical Semantics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lexicalism/">Lexicalism</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear-Algebra/">Linear Algebra</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Logistic-Regression/">Logistic Regression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine/">Machine</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Translation/">Machine Translation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markov/">Markov</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Math/">Math</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matplotlib/">Matplotlib</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Minimum-Edit-Distance/">Minimum Edit Distance</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">31</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Naive-Bayes/">Naive Bayes</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ngram/">Ngram</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NumPy/">NumPy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Orientation/">Orientation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PPMI/">PPMI</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pandas/">Pandas</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Philosophy/">Philosophy</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Phrase-Structure-Grammar/">Phrase Structure Grammar</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Postgresql/">Postgresql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pragmatic-Automatic-Processing/">Pragmatic Automatic Processing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Probabilistic-Grammar/">Probabilistic Grammar</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regex/">Regex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regular-Expression/">Regular Expression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-Learning/">Reinforcement Learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reqular-Expressions/">Reqular Expressions</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SGD/">SGD</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Seaborn/">Seaborn</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Semantic-Automatic-Processing/">Semantic Automatic Processing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sentiment-Classification/">Sentiment Classification</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Simon/">Simon</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Simpson-Paradox/">Simpson Paradox</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Smoothing/">Smoothing</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sort/">Sort</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spell-Check/">Spell Check</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Statistics/">Statistics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Style/">Style</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System/">System</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TF-EDF/">TF-EDF</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Test/">Test</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Text-Normalization/">Text Normalization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Ubuntu/">Ubuntu</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Unity-Operation/">Unity Operation</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vagrant/">Vagrant</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Valence/">Valence</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Vector-Semantics/">Vector Semantics</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VirtualBox/">VirtualBox</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Visualization/">Visualization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Viterbi/">Viterbi</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Word2vec/">Word2vec</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ZhouZhihua/">ZhouZhihua</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Zipf/">Zipf</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/Automatic-Speech-Processing/" style="font-size: 10px;">Automatic Speech Processing</a> <a href="/tags/Backward/" style="font-size: 10px;">Backward</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/Business/" style="font-size: 10px;">Business</a> <a href="/tags/C/" style="font-size: 12px;">C</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/Calculus/" style="font-size: 10px;">Calculus</a> <a href="/tags/Computational-Linguistics/" style="font-size: 10px;">Computational Linguistics</a> <a href="/tags/Computer-Science/" style="font-size: 14px;">Computer Science</a> <a href="/tags/Cosine/" style="font-size: 10px;">Cosine</a> <a href="/tags/Cross-Entropy/" style="font-size: 10px;">Cross Entropy</a> <a href="/tags/DB/" style="font-size: 10px;">DB</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/Data-Clearing/" style="font-size: 10px;">Data Clearing</a> <a href="/tags/Data-Science/" style="font-size: 14px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 14px;">Data Structure</a> <a href="/tags/DeepLearning/" style="font-size: 14px;">DeepLearning</a> <a href="/tags/Dependence/" style="font-size: 10px;">Dependence</a> <a href="/tags/Diary/" style="font-size: 10px;">Diary</a> <a href="/tags/Economics/" style="font-size: 10px;">Economics</a> <a href="/tags/Edit-Distance/" style="font-size: 10px;">Edit Distance</a> <a href="/tags/Embeddings/" style="font-size: 12px;">Embeddings</a> <a href="/tags/Entropy/" style="font-size: 10px;">Entropy</a> <a href="/tags/Evaluation/" style="font-size: 12px;">Evaluation</a> <a href="/tags/F1/" style="font-size: 10px;">F1</a> <a href="/tags/FDW/" style="font-size: 10px;">FDW</a> <a href="/tags/FSM/" style="font-size: 10px;">FSM</a> <a href="/tags/Formal-Analysis/" style="font-size: 10px;">Formal Analysis</a> <a href="/tags/Forward/" style="font-size: 10px;">Forward</a> <a href="/tags/Function-Syntax/" style="font-size: 10px;">Function Syntax</a> <a href="/tags/Gan/" style="font-size: 10px;">Gan</a> <a href="/tags/Gradient-Descent/" style="font-size: 10px;">Gradient Descent</a> <a href="/tags/Grid-Grammar/" style="font-size: 10px;">Grid Grammar</a> <a href="/tags/HMM/" style="font-size: 10px;">HMM</a> <a href="/tags/IE/" style="font-size: 10px;">IE</a> <a href="/tags/Industry/" style="font-size: 10px;">Industry</a> <a href="/tags/Information-Extraction/" style="font-size: 10px;">Information Extraction</a> <a href="/tags/LM/" style="font-size: 12px;">LM</a> <a href="/tags/Language-Model/" style="font-size: 10px;">Language Model</a> <a href="/tags/Lexical-Semantics/" style="font-size: 10px;">Lexical Semantics</a> <a href="/tags/Lexicalism/" style="font-size: 10px;">Lexicalism</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a> <a href="/tags/Machine/" style="font-size: 10px;">Machine</a> <a href="/tags/Machine-Learning/" style="font-size: 10px;">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 10px;">Machine Translation</a> <a href="/tags/Markov/" style="font-size: 10px;">Markov</a> <a href="/tags/Math/" style="font-size: 12px;">Math</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Minimum-Edit-Distance/" style="font-size: 10px;">Minimum Edit Distance</a> <a href="/tags/NLP/" style="font-size: 18px;">NLP</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/Ngram/" style="font-size: 12px;">Ngram</a> <a href="/tags/NumPy/" style="font-size: 10px;">NumPy</a> <a href="/tags/Orientation/" style="font-size: 10px;">Orientation</a> <a href="/tags/PPMI/" style="font-size: 10px;">PPMI</a> <a href="/tags/Pandas/" style="font-size: 10px;">Pandas</a> <a href="/tags/Philosophy/" style="font-size: 12px;">Philosophy</a> <a href="/tags/Phrase-Structure-Grammar/" style="font-size: 10px;">Phrase Structure Grammar</a> <a href="/tags/Postgresql/" style="font-size: 10px;">Postgresql</a> <a href="/tags/Pragmatic-Automatic-Processing/" style="font-size: 10px;">Pragmatic Automatic Processing</a> <a href="/tags/Probabilistic-Grammar/" style="font-size: 10px;">Probabilistic Grammar</a> <a href="/tags/Python/" style="font-size: 16px;">Python</a> <a href="/tags/Regex/" style="font-size: 10px;">Regex</a> <a href="/tags/Regular-Expression/" style="font-size: 10px;">Regular Expression</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10px;">Reinforcement Learning</a> <a href="/tags/Reqular-Expressions/" style="font-size: 10px;">Reqular Expressions</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/tags/Semantic-Automatic-Processing/" style="font-size: 10px;">Semantic Automatic Processing</a> <a href="/tags/Sentiment-Classification/" style="font-size: 10px;">Sentiment Classification</a> <a href="/tags/Simon/" style="font-size: 10px;">Simon</a> <a href="/tags/Simpson-Paradox/" style="font-size: 10px;">Simpson Paradox</a> <a href="/tags/Smoothing/" style="font-size: 10px;">Smoothing</a> <a href="/tags/Sort/" style="font-size: 10px;">Sort</a> <a href="/tags/Spell-Check/" style="font-size: 10px;">Spell Check</a> <a href="/tags/Statistics/" style="font-size: 10px;">Statistics</a> <a href="/tags/Style/" style="font-size: 10px;">Style</a> <a href="/tags/System/" style="font-size: 12px;">System</a> <a href="/tags/TF-EDF/" style="font-size: 10px;">TF-EDF</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Text-Normalization/" style="font-size: 10px;">Text Normalization</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/Unity-Operation/" style="font-size: 10px;">Unity Operation</a> <a href="/tags/Vagrant/" style="font-size: 10px;">Vagrant</a> <a href="/tags/Valence/" style="font-size: 10px;">Valence</a> <a href="/tags/Vector-Semantics/" style="font-size: 10px;">Vector Semantics</a> <a href="/tags/VirtualBox/" style="font-size: 10px;">VirtualBox</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/Viterbi/" style="font-size: 10px;">Viterbi</a> <a href="/tags/Word2vec/" style="font-size: 10px;">Word2vec</a> <a href="/tags/ZhouZhihua/" style="font-size: 10px;">ZhouZhihua</a> <a href="/tags/Zipf/" style="font-size: 10px;">Zipf</a>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2019 Yam
    All rights reserved.</p>
    <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->

</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
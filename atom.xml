<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yam</title>
  <icon>https://www.yam.gift/icon.png</icon>
  <subtitle>Feeling, Coding, Thinking</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.yam.gift/"/>
  <updated>2020-08-22T11:14:40.526Z</updated>
  <id>https://www.yam.gift/</id>
  
  <author>
    <name>Yam</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Search in Rotated Sorted Array (LeetCode 33, 81, 153)</title>
    <link href="https://www.yam.gift/2020/08/22/LeetCode/2020-08-22-Search-in-Rotated-Sorted-Array/"/>
    <id>https://www.yam.gift/2020/08/22/LeetCode/2020-08-22-Search-in-Rotated-Sorted-Array/</id>
    <published>2020-08-22T15:00:00.000Z</published>
    <updated>2020-08-22T11:14:40.526Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Given an integer array &lt;code&gt;nums&lt;/code&gt; sorted in ascending order, and an integer &lt;code&gt;target&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Suppose that &lt;code&gt;nums&lt;/code&gt; is rotated at some pivot unknown to you beforehand (i.e., &lt;code&gt;[0,1,2,4,5,6,7]&lt;/code&gt; might become &lt;code&gt;[4,5,6,7,0,1,2]&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;You should search for &lt;code&gt;target&lt;/code&gt; in &lt;code&gt;nums&lt;/code&gt; and if you found return its index, otherwise return &lt;code&gt;-1&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example 1:&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Input: nums = [4,5,6,7,0,1,2], target = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Output: 4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Example 2:&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Input: nums = [4,5,6,7,0,1,2], target = 3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Output: -1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Example 3:&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Input: nums = [1], target = 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Output: -1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Constraints:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;1 &amp;lt;= nums.length &amp;lt;= 5000&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-10^4 &amp;lt;= nums[i] &amp;lt;= 10^4&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;All values of &lt;code&gt;nums&lt;/code&gt; are &lt;strong&gt;unique&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nums&lt;/code&gt; is guranteed to be rotated at some pivot.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-10^4 &amp;lt;= target &amp;lt;= 10^4&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="Search" scheme="https://www.yam.gift/tags/Search/"/>
    
      <category term="LinkedList" scheme="https://www.yam.gift/tags/LinkedList/"/>
    
      <category term="BiSearch" scheme="https://www.yam.gift/tags/BiSearch/"/>
    
      <category term="Rotated Sorted Array" scheme="https://www.yam.gift/tags/Rotated-Sorted-Array/"/>
    
  </entry>
  
  <entry>
    <title>Swap Nodes in Paris (LeetCode 24)</title>
    <link href="https://www.yam.gift/2020/08/20/LeetCode/2020-08-20-Swap-Nodes-in-Paris/"/>
    <id>https://www.yam.gift/2020/08/20/LeetCode/2020-08-20-Swap-Nodes-in-Paris/</id>
    <published>2020-08-20T15:00:00.000Z</published>
    <updated>2020-08-20T15:35:36.867Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Given a linked list, swap every two adjacent nodes and return its head.&lt;/p&gt;
&lt;p&gt;You may &lt;strong&gt;not&lt;/strong&gt; modify the values in the list’s nodes, only nodes itself may be changed.&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;Given 1-&amp;gt;2-&amp;gt;3-&amp;gt;4, you should return the list as 2-&amp;gt;1-&amp;gt;4-&amp;gt;3.&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="LinkedList" scheme="https://www.yam.gift/tags/LinkedList/"/>
    
      <category term="Swap" scheme="https://www.yam.gift/tags/Swap/"/>
    
      <category term="Recursion" scheme="https://www.yam.gift/tags/Recursion/"/>
    
  </entry>
  
  <entry>
    <title>Hard-SVM, Soft-SVM 和 KKT</title>
    <link href="https://www.yam.gift/2020/08/13/ML/2020-08-13-SVM-Hard-Soft-KKT/"/>
    <id>https://www.yam.gift/2020/08/13/ML/2020-08-13-SVM-Hard-Soft-KKT/</id>
    <published>2020-08-13T04:00:00.000Z</published>
    <updated>2020-08-21T04:16:47.822Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;SVM 是机器学习在神经网络兴起前最经典、有效的算法。它的思想主要是用一个超平面对数据集进行划分，但是能够分开数据集的超平面一般都有无数个，支持向量机的做法是 “间隔最大化”，也就是选择 “支持向量” 到分割平面距离之和最大的，进而将问题转换为一个凸优化问题。&lt;/p&gt;
&lt;p&gt;支持向量机根据数据集可分程度的不同分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线性可分支持向量机：数据线性可分，硬间隔支持向量机&lt;/li&gt;
&lt;li&gt;线性（不可分）支持向量机：数据近似线性可分，软间隔支持向量机&lt;/li&gt;
&lt;li&gt;非线性支持向量机：数据线性不可分，核技巧 + 软间隔最大化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SVM 是一套完整的数据处理算法，核方法的引入使得它具有了对非线性数据的处理能力。具体的方式是将低维数据映射到高维，这样原来不可分的数据自然就可分了。比如假设两类数据点完全是均匀随机分布的，此时如果在平面内无论使用直线还是曲线都无法将它们分开，但假设我们有能力让某一类数据点全部脱离二维进入三维（此处可以想象桌子上散乱着小米和钢珠，你猛地用双手拍桌子，小米会跳起来进入第三维），那它们之间任意的平面都可以轻易将它们隔开。事实上，神经网络使用了类似的方法，感知机的中间隐层做的也是类似的事情。&lt;/p&gt;
&lt;p&gt;本部分只介绍线性可分支持向量机和线性支持向量机。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="Machine Learning" scheme="https://www.yam.gift/tags/Machine-Learning/"/>
    
      <category term="SVM" scheme="https://www.yam.gift/tags/SVM/"/>
    
      <category term="Hard-SVM" scheme="https://www.yam.gift/tags/Hard-SVM/"/>
    
      <category term="Soft-SVM" scheme="https://www.yam.gift/tags/Soft-SVM/"/>
    
      <category term="KKT" scheme="https://www.yam.gift/tags/KKT/"/>
    
      <category term="Hinge Loss" scheme="https://www.yam.gift/tags/Hinge-Loss/"/>
    
  </entry>
  
  <entry>
    <title>Generate Parentheses (LeetCode 22)</title>
    <link href="https://www.yam.gift/2020/08/12/LeetCode/2020-08-12-Generate-Parentheses/"/>
    <id>https://www.yam.gift/2020/08/12/LeetCode/2020-08-12-Generate-Parentheses/</id>
    <published>2020-08-12T15:00:00.000Z</published>
    <updated>2020-08-14T16:16:05.266Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Given &lt;em&gt;n&lt;/em&gt; pairs of parentheses, write a function to generate all combinations of well-formed parentheses.&lt;/p&gt;
&lt;p&gt;For example, given &lt;em&gt;n&lt;/em&gt; = 3, a solution set is:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&quot;((()))&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&quot;(()())&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&quot;(())()&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&quot;()(())&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&quot;()()()&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="Recursion" scheme="https://www.yam.gift/tags/Recursion/"/>
    
      <category term="Backtracking" scheme="https://www.yam.gift/tags/Backtracking/"/>
    
      <category term="Catalan" scheme="https://www.yam.gift/tags/Catalan/"/>
    
      <category term="Stirling" scheme="https://www.yam.gift/tags/Stirling/"/>
    
  </entry>
  
  <entry>
    <title>AI 小课堂：Activation Function</title>
    <link href="https://www.yam.gift/2020/07/05/AIBK/2020-07-05-Activation/"/>
    <id>https://www.yam.gift/2020/07/05/AIBK/2020-07-05-Activation/</id>
    <published>2020-07-05T15:00:00.000Z</published>
    <updated>2020-07-06T03:37:31.000Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;基本思想&quot;&gt;&lt;a href=&quot;#基本思想&quot; class=&quot;headerlink&quot; title=&quot;基本思想&quot;&gt;&lt;/a&gt;基本思想&lt;/h2&gt;&lt;p&gt;激活函数在深度学习中的作用就跟神经元中 “细胞体” 的功能类似：确定输出中哪些要被激活。我们都知道 SVM 通过核方法对非线性可分的数据进行分类，这其实是一种提升的方法（机器学习中很多问题都是类似的降个维度或升个维度）。为啥提升维度就能够让原本线性不可分的数据可分呢？我们以下图为例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://qnimg.lovevivian.cn/aitc-activation-2.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;两组不同标签的数据构成一个近似的同心圆。要想将两种不同的点分开，靠二维的一条直线肯定是没办法了，此时我们可以把数据映射到三维空间，我们可以想象让同心圆之间再插入一个圆，然后让这个圆以内的整块都凸起来，也就是让它脱离原来的维度。这时候我们只要在两个平面中间任意选择一个平面就可以将数据集分开了。那这和我们的激活函数有啥关系呢？其实激活函数所提供的 “非线性” 变换正是类似的方式。也就是说，只要有非线性的激活函数，三层（输入、1 个隐层、输出层）的神经网络理论上可以逼近任意函数。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="Activation" scheme="https://www.yam.gift/tags/Activation/"/>
    
      <category term="GELU" scheme="https://www.yam.gift/tags/GELU/"/>
    
      <category term="RELU" scheme="https://www.yam.gift/tags/RELU/"/>
    
      <category term="Sigmoid" scheme="https://www.yam.gift/tags/Sigmoid/"/>
    
      <category term="Softmax" scheme="https://www.yam.gift/tags/Softmax/"/>
    
      <category term="TanH" scheme="https://www.yam.gift/tags/TanH/"/>
    
  </entry>
  
  <entry>
    <title>QA 小课堂：Introduction</title>
    <link href="https://www.yam.gift/2020/07/05/AIQA/2020-07-05-Introduction/"/>
    <id>https://www.yam.gift/2020/07/05/AIQA/2020-07-05-Introduction/</id>
    <published>2020-07-05T03:00:00.000Z</published>
    <updated>2020-07-06T03:37:55.000Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;说明：仅用于学习和技术交流，不提供任何投资建议。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;基本流程&quot;&gt;&lt;a href=&quot;#基本流程&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="Quant" scheme="https://www.yam.gift/tags/Quant/"/>
    
  </entry>
  
  <entry>
    <title>DeBERTa 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/06/27/Paper/2020-06-27-DeBERTa/"/>
    <id>https://www.yam.gift/2020/06/27/Paper/2020-06-27-DeBERTa/</id>
    <published>2020-06-27T15:00:00.000Z</published>
    <updated>2020-06-29T03:22:27.148Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2006.03654&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2006.03654] DeBERTa: Decoding-enhanced BERT with Disentangled Attention&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/microsoft/DeBERTa&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;microsoft/DeBERTa: The implementation of DeBERTa&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：增加位置-内容与内容-位置的自注意力增强位置和内容之间的依赖，用 EMD 缓解 BERT 预训练和精调因为 MASK 造成的不匹配问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="Bert" scheme="https://www.yam.gift/tags/Bert/"/>
    
      <category term="DeBERTa" scheme="https://www.yam.gift/tags/DeBERTa/"/>
    
      <category term="Disentangled Attention" scheme="https://www.yam.gift/tags/Disentangled-Attention/"/>
    
      <category term="EMD" scheme="https://www.yam.gift/tags/EMD/"/>
    
  </entry>
  
  <entry>
    <title>RoBERTa 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/06/25/Paper/2020-06-25-RoBERTa/"/>
    <id>https://www.yam.gift/2020/06/25/Paper/2020-06-25-RoBERTa/</id>
    <published>2020-06-25T13:00:00.000Z</published>
    <updated>2020-06-25T13:12:06.844Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/1907.11692&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[1907.11692] RoBERTa: A Robustly Optimized BERT Pretraining Approach&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/pytorch/fairseq/tree/master/examples/roberta&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;fairseq/examples/roberta at master · pytorch/fairseq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：&lt;/p&gt;
&lt;p&gt;对 BERT 几个小点（主要是动态 Mask 和不使用 NSP）进行优化取得了比较好的实践结果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Bert" scheme="https://www.yam.gift/tags/Bert/"/>
    
      <category term="RoBERTa" scheme="https://www.yam.gift/tags/RoBERTa/"/>
    
      <category term="Dynamic-Mask" scheme="https://www.yam.gift/tags/Dynamic-Mask/"/>
    
  </entry>
  
  <entry>
    <title>Bart 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/06/13/Paper/2020-06-13-Bart/"/>
    <id>https://www.yam.gift/2020/06/13/Paper/2020-06-13-Bart/</id>
    <published>2020-06-13T15:00:00.000Z</published>
    <updated>2020-06-14T03:49:13.042Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1910.13461.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1910.13461.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/pytorch/fairseq&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/pytorch/fairseq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：基于 Transformer Seq2Seq 架构适应各种不同的输入噪声。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="Bart" scheme="https://www.yam.gift/tags/Bart/"/>
    
  </entry>
  
  <entry>
    <title>ALBERT 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/05/10/Paper/2020-05-10-ALBERT/"/>
    <id>https://www.yam.gift/2020/05/10/Paper/2020-05-10-ALBERT/</id>
    <published>2020-05-10T15:00:00.000Z</published>
    <updated>2020-05-11T04:57:20.486Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1909.11942.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1909.11942.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/google-research/ALBERT&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;google-research/albert: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：基于 Bert 的改进版本：分解 Embedding 参数、层间参数共享、SOP 替代 NSP。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Bert" scheme="https://www.yam.gift/tags/Bert/"/>
    
      <category term="ALBERT" scheme="https://www.yam.gift/tags/ALBERT/"/>
    
  </entry>
  
  <entry>
    <title>From Python to Engineer</title>
    <link href="https://www.yam.gift/2020/05/01/Collection/From-Python-to-Engineer/"/>
    <id>https://www.yam.gift/2020/05/01/Collection/From-Python-to-Engineer/</id>
    <published>2020-05-01T06:00:08.000Z</published>
    <updated>2020-07-06T01:21:17.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Python is one the most popular programming languages nowadays. It’s easy to learn and use. Maybe Python is your best choice if you want to be an engineer in future, or you want to work with programming.  Here I list many kinds of materials most of which comes from my collection. Hope this could help you to start your programming road. It might be a little hard, but a lot of fun as well. Let’s go.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I will update this blog continually when it needs to. By the way, If you are a very beginner to AI or computer, I recommend you read &lt;a href=&quot;https://github.com/hscspring/AIToolBox&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;AIToolBox&lt;/a&gt; first.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Table-of-Contents&quot;&gt;&lt;a href=&quot;#Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot;Table of Contents&quot;&gt;&lt;/a&gt;Table of Contents&lt;/h2&gt;&lt;div class=&quot;toc&quot;&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Skill&quot; data-toc-modified-id=&quot;Skill-1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Skill&lt;/a&gt;&lt;/span&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Basic&quot; data-toc-modified-id=&quot;Basic-1.1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Basic&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Trick&quot; data-toc-modified-id=&quot;Trick-1.2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.2&amp;nbsp;&amp;nbsp;&lt;/span&gt;Trick&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#State&quot; data-toc-modified-id=&quot;State-1.3&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.3&amp;nbsp;&amp;nbsp;&lt;/span&gt;State&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Pipe&quot; data-toc-modified-id=&quot;Pipe-1.4&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.4&amp;nbsp;&amp;nbsp;&lt;/span&gt;Pipe&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#FP&quot; data-toc-modified-id=&quot;FP-1.5&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.5&amp;nbsp;&amp;nbsp;&lt;/span&gt;FP&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Datastructure-and-Algorithm&quot; data-toc-modified-id=&quot;Datastructure-and-Algorithm-1.6&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;1.6&amp;nbsp;&amp;nbsp;&lt;/span&gt;Datastructure and Algorithm&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#AI&quot; data-toc-modified-id=&quot;AI-2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2&amp;nbsp;&amp;nbsp;&lt;/span&gt;AI&lt;/a&gt;&lt;/span&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Deploy&quot; data-toc-modified-id=&quot;Deploy-2.1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2.1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Deploy&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Toolkit&quot; data-toc-modified-id=&quot;Toolkit-2.2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2.2&amp;nbsp;&amp;nbsp;&lt;/span&gt;Toolkit&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#DataAnnotation&quot; data-toc-modified-id=&quot;DataAnnotation-2.3&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2.3&amp;nbsp;&amp;nbsp;&lt;/span&gt;DataAnnotation&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#DeepLearning&quot; data-toc-modified-id=&quot;DeepLearning-2.4&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2.4&amp;nbsp;&amp;nbsp;&lt;/span&gt;DeepLearning&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#MachineLearning&quot; data-toc-modified-id=&quot;MachineLearning-2.5&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;2.5&amp;nbsp;&amp;nbsp;&lt;/span&gt;MachineLearning&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Engineering&quot; data-toc-modified-id=&quot;Engineering-3&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3&amp;nbsp;&amp;nbsp;&lt;/span&gt;Engineering&lt;/a&gt;&lt;/span&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Design&quot; data-toc-modified-id=&quot;Design-3.1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Design&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Test&quot; data-toc-modified-id=&quot;Test-3.2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.2&amp;nbsp;&amp;nbsp;&lt;/span&gt;Test&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Style&quot; data-toc-modified-id=&quot;Style-3.3&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.3&amp;nbsp;&amp;nbsp;&lt;/span&gt;Style&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Profile&quot; data-toc-modified-id=&quot;Profile-3.4&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.4&amp;nbsp;&amp;nbsp;&lt;/span&gt;Profile&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Safety&quot; data-toc-modified-id=&quot;Safety-3.5&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.5&amp;nbsp;&amp;nbsp;&lt;/span&gt;Safety&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Distribute&quot; data-toc-modified-id=&quot;Distribute-3.6&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.6&amp;nbsp;&amp;nbsp;&lt;/span&gt;Distribute&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#FrameWork&quot; data-toc-modified-id=&quot;FrameWork-3.7&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.7&amp;nbsp;&amp;nbsp;&lt;/span&gt;FrameWork&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Boilerplate&quot; data-toc-modified-id=&quot;Boilerplate-3.8&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.8&amp;nbsp;&amp;nbsp;&lt;/span&gt;Boilerplate&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#JWT&quot; data-toc-modified-id=&quot;JWT-3.9&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.9&amp;nbsp;&amp;nbsp;&lt;/span&gt;JWT&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Coroutine&quot; data-toc-modified-id=&quot;Coroutine-3.10&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.10&amp;nbsp;&amp;nbsp;&lt;/span&gt;Coroutine&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Concurrency&quot; data-toc-modified-id=&quot;Concurrency-3.11&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.11&amp;nbsp;&amp;nbsp;&lt;/span&gt;Concurrency&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Memory&quot; data-toc-modified-id=&quot;Memory-3.12&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.12&amp;nbsp;&amp;nbsp;&lt;/span&gt;Memory&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#API&quot; data-toc-modified-id=&quot;API-3.13&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.13&amp;nbsp;&amp;nbsp;&lt;/span&gt;API&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#gRPC&quot; data-toc-modified-id=&quot;gRPC-3.14&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.14&amp;nbsp;&amp;nbsp;&lt;/span&gt;gRPC&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Database&quot; data-toc-modified-id=&quot;Database-3.15&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.15&amp;nbsp;&amp;nbsp;&lt;/span&gt;Database&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Project&quot; data-toc-modified-id=&quot;Project-3.16&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;3.16&amp;nbsp;&amp;nbsp;&lt;/span&gt;Project&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Tool&quot; data-toc-modified-id=&quot;Tool-4&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4&amp;nbsp;&amp;nbsp;&lt;/span&gt;Tool&lt;/a&gt;&lt;/span&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Spider&quot; data-toc-modified-id=&quot;Spider-4.1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Spider&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Audio&quot; data-toc-modified-id=&quot;Audio-4.2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.2&amp;nbsp;&amp;nbsp;&lt;/span&gt;Audio&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Chat&quot; data-toc-modified-id=&quot;Chat-4.3&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.3&amp;nbsp;&amp;nbsp;&lt;/span&gt;Chat&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Text&quot; data-toc-modified-id=&quot;Text-4.4&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.4&amp;nbsp;&amp;nbsp;&lt;/span&gt;Text&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Task&quot; data-toc-modified-id=&quot;Task-4.5&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.5&amp;nbsp;&amp;nbsp;&lt;/span&gt;Task&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Visualization&quot; data-toc-modified-id=&quot;Visualization-4.6&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.6&amp;nbsp;&amp;nbsp;&lt;/span&gt;Visualization&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Logic&quot; data-toc-modified-id=&quot;Logic-4.7&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;4.7&amp;nbsp;&amp;nbsp;&lt;/span&gt;Logic&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Comprehensive&quot; data-toc-modified-id=&quot;Comprehensive-5&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;5&amp;nbsp;&amp;nbsp;&lt;/span&gt;Comprehensive&lt;/a&gt;&lt;/span&gt;&lt;ul class=&quot;toc-item&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Resources&quot; data-toc-modified-id=&quot;Resources-5.1&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;5.1&amp;nbsp;&amp;nbsp;&lt;/span&gt;Resources&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;#Courses&quot; data-toc-modified-id=&quot;Courses-5.2&quot;&gt;&lt;span class=&quot;toc-item-num&quot;&gt;5.2&amp;nbsp;&amp;nbsp;&lt;/span&gt;Courses&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="Python" scheme="https://www.yam.gift/tags/Python/"/>
    
      <category term="DeepLearning" scheme="https://www.yam.gift/tags/DeepLearning/"/>
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>多贝里《清醒思考的艺术》读书笔记</title>
    <link href="https://www.yam.gift/2020/04/28/Mind/2020-04-28-The-Art-of-Clearly-Thinking/"/>
    <id>https://www.yam.gift/2020/04/28/Mind/2020-04-28-The-Art-of-Clearly-Thinking/</id>
    <published>2020-04-28T06:00:00.000Z</published>
    <updated>2020-04-28T07:43:50.332Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;52 个思维偏误和提示清单：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;幸存偏误：多看看失败的事，自然会发现成功并不是他们所说的那样。&lt;br&gt;游泳选手身材错觉：因为他那样，所以他看起来才这样。你想成为这样，你得先那样。&lt;br&gt;过度自信效应：大家都会盲目自信，但请你作好最坏打算。还记得查理芒格说的吗，知道自己可能死在哪里才不会去那里。&lt;br&gt;从众心理：你行为上可以去从众，但思想上一定要保持独立。&lt;br&gt;纠缠于沉没成本：千万别被过去影响，基于现在和未来判断！当断不断反受其乱！&lt;br&gt;互惠偏误：一段感情（关系）确定之前，多欠别人的；确定之后，全心全意。商业或普通关系，相反，直到变成你想要的为止。&lt;br&gt;确认偏误之一：随时准备好反驳自己并及时反驳，因为你没那么牛逼，也没那么幸运，世界更没那么简单，但你会自己骗自己。&lt;br&gt;确认偏误之二：不带任何色彩地重新审视，要注意精确和反驳证据。切忌先入为主。&lt;br&gt;权威偏误：大胆藐视权威吧，他可能比你好不到哪里去。&lt;br&gt;对比效应：为别人建立基准线，避免自己被基准线困扰。&lt;br&gt;现成偏误：千万别把经验当做理由。&lt;br&gt;在好转之前会先恶化陷阱：虽然无法预测未来，但也不要拿经验当依据，而应该看过程中的各项指标情况。&lt;br&gt;故事偏误：对一切故事保持足够理性，拆了它，解剖它；但，学会给别人讲故事。。&lt;br&gt;事后诸葛亮偏误：没事别瞎BB，更别轻易下结论。俗话说：“你知道个鸟。”&lt;br&gt;司机的知识：别像赵括一样。万一遇到这种人，呵呵就行了。&lt;br&gt;控制错觉：你基本上影响不了什么，正确认识问题和自己真正能影响的。&lt;br&gt;激励过敏倾向：任何难以理解的事其实只是你没发现其中的“因”。要控制“因”，比如提前约定服务价格。&lt;br&gt;回归均值：很多时候变好或变坏和你做一些不相干的事情没什么关系，那只是周期性的 “回归均值”。&lt;br&gt;公地悲剧：如果可能获得好处而又不损失什么，人类最喜欢了。&lt;br&gt;结果偏误：关注结果，更加关注过程以及其他条件。&lt;br&gt;选择的悖论：不忘初心，方得始终。&lt;br&gt;讨喜偏误：能接受我的不好，才能拥有我的好。先想着不好。&lt;br&gt;禀赋效应：赤条条来赤条条走，该舍当舍。&lt;br&gt;奇迹：小概率不等于零概率，只所以你觉得怪是因为你见得少。&lt;br&gt;团体迷思：无论何时，只要需要，请发表你独立思考得来的观点。&lt;br&gt;忽视概率偏误：用数字说话，可以的话，懂点统计学。&lt;br&gt;零风险偏误：明白一个道理，没有什么是确定的，唯一确定的是不确定本身。&lt;br&gt;稀少性谬误：关注作用和需要而不要关注稀缺性。&lt;br&gt;忽视基本概率：不要用绝对概率，用贝叶斯概率，即不要忽视基本概率。&lt;br&gt;赌徒谬误：如果是独立的随机事件，那它每一次都如第一次。&lt;br&gt;锚定效应：在不对称信息下，请警惕锚定效应。&lt;br&gt;归纳法：不要错误估计个人对系统的影响力，即使方法没问题。&lt;br&gt;规避损失：面对 “损失” 理性一点。&lt;br&gt;社会性懈怠：权力责任到人，突显个人效率。&lt;br&gt;指数增长：事关增长率时，不要相信感觉。&lt;br&gt;赢家的诅咒：不要参与拍卖。&lt;br&gt;基本特征谬误：关注情境或事物而不只是人。&lt;br&gt;错误的因果关系：相关只是表面，因果方为本质。&lt;br&gt;光环效应：客观、理性，只关注当下关注的点（说起来就是这么容易）。&lt;br&gt;替代途径：客观、基于数据衡量收益和风险。&lt;br&gt;预测的错觉：条件反射地对预测持谨慎态度。&lt;br&gt;关联谬误：做重要决定时不要轻信自己的直觉。&lt;br&gt;框架效应：时刻注意框架效应的影响，剔除所有无关描述，只关注信息。&lt;br&gt;行动偏误：如果情况不明，不要采取任何行动。&lt;br&gt;不作为偏误：不作为可以是一时的选择，但不要成为永久的策略。&lt;br&gt;自利偏误：找个直言不讳的朋友或者让对手来评价你。&lt;br&gt;享乐适应症：把时间花在你真正爱做的事情上。&lt;br&gt;自我选择偏误：当你觉得自己倒霉时，先想想这是不是本来就是个概率事件。&lt;br&gt;联想偏误：客观分析、就事论事，不要胡思乱想。&lt;br&gt;新手的运气：别多想，没有什么新手运气。&lt;br&gt;认知失调：承认自己的错误需要很大的勇气，但好过掩耳盗铃。&lt;br&gt;双曲贴现：自制力很难，但很有必要。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="Thought" scheme="https://www.yam.gift/tags/Thought/"/>
    
      <category term="Cognition" scheme="https://www.yam.gift/tags/Cognition/"/>
    
      <category term="Psychology" scheme="https://www.yam.gift/tags/Psychology/"/>
    
  </entry>
  
  <entry>
    <title>DistilBERT 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/04/27/Paper/2020-04-27-DistilBERT/"/>
    <id>https://www.yam.gift/2020/04/27/Paper/2020-04-27-DistilBERT/</id>
    <published>2020-04-27T15:00:00.000Z</published>
    <updated>2020-05-03T03:28:51.771Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1910.01108.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1910.01108.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/huggingface/transformers/tree/master/examples/distillation&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;transformers/examples/distillation at master · huggingface/transformers&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：通过知识蒸馏（在 logits，hidden_states 上计算学生与教师的 loss）训练一个小（主要是层数）模型实现和大模型类似的效果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Bert" scheme="https://www.yam.gift/tags/Bert/"/>
    
      <category term="DistilBERT" scheme="https://www.yam.gift/tags/DistilBERT/"/>
    
  </entry>
  
  <entry>
    <title>Transformer 代码笔记</title>
    <link href="https://www.yam.gift/2020/04/23/Paper/2020-04-23-Transformer/"/>
    <id>https://www.yam.gift/2020/04/23/Paper/2020-04-23-Transformer/</id>
    <published>2020-04-23T15:00:00.000Z</published>
    <updated>2020-05-07T08:21:40.143Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;之前写过一篇关于 &lt;a href=&quot;https://arxiv.org/pdf/1706.03762.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Attention Is All You Need&lt;/a&gt; 的 &lt;a href=&quot;https://yam.gift/2019/08/04/Paper/2019-08-04-Transformer-Paper/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文笔记&lt;/a&gt;，不过那时候写的笔记都没有深入 Code 环节，再加上其实已经有了一篇 &lt;a href=&quot;http://nlp.seas.harvard.edu/2018/04/03/attention.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Annotated Transformer&lt;/a&gt;，也没必要做重复工作。不过现在 Transformer 已经大放异彩到几乎成为了标准配件，所以觉得有必要单独拿出来就组件角度再次学习一遍，于是就有了这篇文章。&lt;/p&gt;
&lt;p&gt;本文代码主要基于 &lt;a href=&quot;https://github.com/OpenNMT/OpenNMT-py&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;OpenNMT&lt;/a&gt;，另外也参考了一点 &lt;a href=&quot;https://github.com/pytorch/fairseq&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;fairseq&lt;/a&gt;，这俩都是 PyTorch 实现的。Tensorflow 实现的版本相对更多一些，详见 Appendix 部分。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Attention" scheme="https://www.yam.gift/tags/Attention/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="Self-Attention" scheme="https://www.yam.gift/tags/Self-Attention/"/>
    
      <category term="Multi-Head Attention" scheme="https://www.yam.gift/tags/Multi-Head-Attention/"/>
    
      <category term="Encoder" scheme="https://www.yam.gift/tags/Encoder/"/>
    
      <category term="Decoder" scheme="https://www.yam.gift/tags/Decoder/"/>
    
  </entry>
  
  <entry>
    <title>Luong Attention 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/04/14/Paper/2020-04-14-Luong-Attention/"/>
    <id>https://www.yam.gift/2020/04/14/Paper/2020-04-14-Luong-Attention/</id>
    <published>2020-04-14T04:00:00.000Z</published>
    <updated>2020-05-03T03:29:19.254Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1508.04025v5.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1508.04025v5.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：文章未提供，见 Appendix&lt;/p&gt;
&lt;p&gt;核心思想：通过在 Decoder 的每一步使用 Encoder 信息，并对 Encoder 信息赋予不同权重来获得更好的 Decoder 结果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Attention" scheme="https://www.yam.gift/tags/Attention/"/>
    
      <category term="Luong Attention" scheme="https://www.yam.gift/tags/Luong-Attention/"/>
    
  </entry>
  
  <entry>
    <title>GPT-2 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/04/07/Paper/2020-04-07-GPT2/"/>
    <id>https://www.yam.gift/2020/04/07/Paper/2020-04-07-GPT2/</id>
    <published>2020-04-07T04:00:00.000Z</published>
    <updated>2020-05-03T03:29:30.011Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper: &lt;a href=&quot;https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/openai/gpt-2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;openai/gpt-2: Code for the paper “Language Models are Unsupervised Multitask Learners”&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/minimaxir/gpt-2-simple&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;minimaxir/gpt-2-simple: Python package to easily retrain OpenAI’s GPT-2 text-generating model on new texts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;核心思想：基于 Transformer 的更加 General 的语言模型。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="GPT-2" scheme="https://www.yam.gift/tags/GPT-2/"/>
    
      <category term="Language Model" scheme="https://www.yam.gift/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Node2Vec 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/03/30/Paper/2020-03-30-Node2Vec/"/>
    <id>https://www.yam.gift/2020/03/30/Paper/2020-03-30-Node2Vec/</id>
    <published>2020-03-30T15:55:00.000Z</published>
    <updated>2020-05-03T03:29:44.791Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1607.00653.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;node2vec: Scalable Feature Learning for Networks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/aditya-grover/node2vec&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;aditya-grover/node2vec&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：通过给网络节点的邻居定义一个灵活的概念，并设计了一个能够有效探索邻居多样性的有偏随机游走程序，来学习网络的节点表征。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Graph" scheme="https://www.yam.gift/tags/Graph/"/>
    
      <category term="node2vec" scheme="https://www.yam.gift/tags/node2vec/"/>
    
      <category term="DeepGraph" scheme="https://www.yam.gift/tags/DeepGraph/"/>
    
  </entry>
  
  <entry>
    <title>TextRank Keyword Extraction 论文+代码笔记</title>
    <link href="https://www.yam.gift/2020/03/21/Paper/2020-03-21-Text-Rank/"/>
    <id>https://www.yam.gift/2020/03/21/Paper/2020-03-21-Text-Rank/</id>
    <published>2020-03-21T10:00:00.000Z</published>
    <updated>2020-05-03T03:34:31.873Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://www.aclweb.org/anthology/W04-3252.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;TextRank: Bringing Order into Texts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码：&lt;a href=&quot;https://github.com/networkx/networkx/blob/master/networkx/algorithms/link_analysis/pagerank_alg.py&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;networkx/pagerank_alg.py at master · networkx/networkx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;核心思想：TextRank 是基于 Google PageRank 的一种关键词（句子）提取方法，它的本质是对文本 Token 按窗口构建节点和边（实际为节点在一定窗口范围内的共现关系），根据 PageRank 得到节点的 Score 排序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Graph" scheme="https://www.yam.gift/tags/Graph/"/>
    
      <category term="Keyword" scheme="https://www.yam.gift/tags/Keyword/"/>
    
      <category term="TextRank" scheme="https://www.yam.gift/tags/TextRank/"/>
    
      <category term="PageRank" scheme="https://www.yam.gift/tags/PageRank/"/>
    
  </entry>
  
  <entry>
    <title>Reformer, The Efficient Transformer 论文笔记</title>
    <link href="https://www.yam.gift/2020/02/15/Paper/2020-02-15-Reformer-Paper/"/>
    <id>https://www.yam.gift/2020/02/15/Paper/2020-02-15-Reformer-Paper/</id>
    <published>2020-02-15T09:00:00.000Z</published>
    <updated>2020-08-23T10:38:30.289Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;paper: &lt;a href=&quot;https://arxiv.org/abs/2001.04451&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Reformer: The Efficient Transformer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;code: &lt;a href=&quot;https://github.com/google/trax/tree/master/trax/models/reformer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;trax/trax/models/reformer at master · google/trax&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;Transformer 在训练时成本过高（尤其是长句子），文章提出两种改进方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将点乘的 attention 替换为局部敏感哈希，复杂度从 O(N^2) 降为 O(N logN)，N 为句子长度。&lt;/li&gt;
&lt;li&gt;标准残差 Layer 替换为可逆残差 Layer，使得训练中只存储一次激活值，而不是 N 次，N 为 Layer 数量。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="Reformer" scheme="https://www.yam.gift/tags/Reformer/"/>
    
  </entry>
  
  <entry>
    <title>Bahdanau Attention 论文笔记</title>
    <link href="https://www.yam.gift/2020/02/08/Paper/2020-02-08-Bahdanau-Attention-Paper/"/>
    <id>https://www.yam.gift/2020/02/08/Paper/2020-02-08-Bahdanau-Attention-Paper/</id>
    <published>2020-02-08T09:00:00.000Z</published>
    <updated>2020-05-03T03:30:16.855Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;paper: &lt;a href=&quot;https://arxiv.org/pdf/1409.0473.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1409.0473.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;作者猜测 encoder 中使用固定长度的向量（即将句子编码成一个固定长度的向量）可能是 performance 的瓶颈。因此提出一种能够自动 search 源句子中与预测词相关的部分。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Attention" scheme="https://www.yam.gift/tags/Attention/"/>
    
      <category term="Bahdanau Attention" scheme="https://www.yam.gift/tags/Bahdanau-Attention/"/>
    
  </entry>
  
</feed>

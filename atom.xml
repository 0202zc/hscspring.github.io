<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yam</title>
  <icon>https://www.yam.gift/icon.png</icon>
  <subtitle>Feeling, Coding, Thinking</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.yam.gift/"/>
  <updated>2022-10-16T14:50:04.103Z</updated>
  <id>https://www.yam.gift/</id>
  
  <author>
    <name>Yam</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Global Pointer：Novel Efficient Span-based Approach for NER</title>
    <link href="https://www.yam.gift/2022/10/16/Paper/2022-10-16-GlobalPointer/"/>
    <id>https://www.yam.gift/2022/10/16/Paper/2022-10-16-GlobalPointer/</id>
    <published>2022-10-16T15:00:00.000Z</published>
    <updated>2022-10-16T14:50:04.103Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2208.03054&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2208.03054] Global Pointer: Novel Efficient Span-based Approach for Named Entity Recognition&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/bojone/bert4keras&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/bojone/bert4keras&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：全局指针识别 NER，Span 预测得到 NER 类型。&lt;/p&gt;
&lt;p&gt;摘要：NER 任务是从一段文本中识别出预先定义的语义实体类型。SOTA 方案通常会因为捕获底层文本的细粒度语义信息而受到影响。基于 Span 的方法克服了这种缺陷，但性能是个问题。本文提出基于 Span 的 NER 框架——全局指针（GP），通过乘法注意力机制利用相对位置，目标是考虑开始和结束位置的全局视图来预测实体。除了设计了两个模块（Token 表征和 Span 预测）来识别实体外，还引入了一种新的损失函数来解决标签不均衡问题，另外还引入了一种简单有效的近似方法减少参数。实验表明 GP 胜过现有方案，此外损失函数也表现出有效性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="NER" scheme="https://www.yam.gift/tags/NER/"/>
    
      <category term="Span" scheme="https://www.yam.gift/tags/Span/"/>
    
      <category term="GP" scheme="https://www.yam.gift/tags/GP/"/>
    
      <category term="Global Pointer" scheme="https://www.yam.gift/tags/Global-Pointer/"/>
    
      <category term="Class Imbalance Loss" scheme="https://www.yam.gift/tags/Class-Imbalance-Loss/"/>
    
  </entry>
  
  <entry>
    <title>DeepGen：Diverse Search Ad Generation and Real-Time Customization</title>
    <link href="https://www.yam.gift/2022/10/15/Paper/2022-10-15-DeepGen/"/>
    <id>https://www.yam.gift/2022/10/15/Paper/2022-10-15-DeepGen/</id>
    <published>2022-10-15T15:00:00.000Z</published>
    <updated>2022-10-16T12:19:36.803Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2208.03438&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2208.03438] DeepGen: Diverse Search Ad Generation and Real-Time Customization&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：无&lt;/p&gt;
&lt;p&gt;一句话概述：端到端广告文本生成方案。&lt;/p&gt;
&lt;p&gt;摘要：DeepGen 是一个 Web 部署的用于为 Bing 广告客户自动生成搜索广告的系统。它使用最新的 NLG 模型从广告商的网页生成流畅的广告，并解决一些实际问题（真实性、推理速度）。系统会根据用户的搜索查询实时创建定制化广告，从而根据用户「正在寻找的内容」突出显示同一产品的不同方面。为了实现此目标，系统提前生成各种可选择的小广告片段素材，查询时选择最相关的拼接到完整广告中。通过训练可控 NLG 模型为同一网页生成多个广告，突出不同卖点，从而提高生成的多样性。更进一步，通过首先运行使用不同目标训练的生成模型集合，然后使用多样性采样算法选择不同生成结果子集进行在线选择，进一步横向提升了多样性。实验结果验证了系统设计的有效性，目前已部署生产环境，提供了必应投放的大约 4% 的全球广告。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="NLG" scheme="https://www.yam.gift/tags/NLG/"/>
    
      <category term="DeepGen" scheme="https://www.yam.gift/tags/DeepGen/"/>
    
  </entry>
  
  <entry>
    <title>只如初见的不只爱情</title>
    <link href="https://www.yam.gift/2022/09/11/Diary/2022-09-11-Passion/"/>
    <id>https://www.yam.gift/2022/09/11/Diary/2022-09-11-Passion/</id>
    <published>2022-09-11T15:00:00.000Z</published>
    <updated>2022-09-11T15:51:39.779Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;很久没有静心写一些文字了，回顾近大半年，感觉好像每天都在忙，时刻都有未做完的任务，时间就这样一点点慢慢流逝，安静的让人毫无知觉。&lt;/p&gt;
&lt;p&gt;今天是 2022 年中秋假的第二天，第一天睡了大半天，第二天浑浑噩噩待了近一个白天，大脑完全不想动，只想着到处刷刷，随便刷什么。这不是在打发时间，只是一种大脑潜意识或有意识地在「放纵」，提不起精气神干任何该干的事。躺着刷手机到下午 6 点多，突然觉得应该下楼走走，于是一边遛狗，一边慢慢开始自己与自己的对话。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Thinking" scheme="https://www.yam.gift/categories/Thinking/"/>
    
    
      <category term="Diary" scheme="https://www.yam.gift/tags/Diary/"/>
    
      <category term="Passion" scheme="https://www.yam.gift/tags/Passion/"/>
    
      <category term="Life" scheme="https://www.yam.gift/tags/Life/"/>
    
      <category term="Growth" scheme="https://www.yam.gift/tags/Growth/"/>
    
  </entry>
  
  <entry>
    <title>FLAN：Fine-tuned Language Models are Zero-Shot Learners</title>
    <link href="https://www.yam.gift/2022/08/28/Paper/2022-08-28-FLAN/"/>
    <id>https://www.yam.gift/2022/08/28/Paper/2022-08-28-FLAN/</id>
    <published>2022-08-28T15:00:00.000Z</published>
    <updated>2022-08-28T09:47:47.474Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2109.01652&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2109.01652] Finetuned Language Models Are Zero-Shot Learners&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/google-research/flan&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/google-research/flan&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：指示微调赋予 MTL Zero-Shot 能力。&lt;/p&gt;
&lt;p&gt;摘要：本文探索了一种简单的方法来提升语言模型的 Zero-Shot 能力——指示（或指令）微调（instruction tuning），在一组通过指示描述的数据集上对语言模型微调，大大提高了在未见过任务上的 Zero-Shot 能力。模型 137B，在超过 60 个使用描述模板描述的数据集上微调。FLAN 在 20/25 个任务上超过了 175B 的 GPT3，Few-Shot 能力也大部分超过了 GPT3。消融实结果发现，微调的数据集数量、模型规模、指示，这三个因素是指示微调的关键。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="NLG" scheme="https://www.yam.gift/tags/NLG/"/>
    
      <category term="Prompt" scheme="https://www.yam.gift/tags/Prompt/"/>
    
      <category term="MTL" scheme="https://www.yam.gift/tags/MTL/"/>
    
      <category term="FLAN" scheme="https://www.yam.gift/tags/FLAN/"/>
    
      <category term="Zero-Shot" scheme="https://www.yam.gift/tags/Zero-Shot/"/>
    
  </entry>
  
  <entry>
    <title>W2NER 代码</title>
    <link href="https://www.yam.gift/2022/07/17/Paper/2022-07-17-W2NER-Code/"/>
    <id>https://www.yam.gift/2022/07/17/Paper/2022-07-17-W2NER-Code/</id>
    <published>2022-07-17T15:00:00.000Z</published>
    <updated>2022-07-17T14:23:23.236Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文主要讲述 W2NER 的代码，关于论文相关部分可阅读：&lt;a href=&quot;https://yam.gift/2022/06/11/Paper/2022-06-11-W2NER/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;统一NER为词词关系分类 | Yam&lt;/a&gt;。代码主要包括：输入、训练输出和解码部分，对于模型部分可参考前面的链接。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="NER" scheme="https://www.yam.gift/tags/NER/"/>
    
      <category term="W2NER" scheme="https://www.yam.gift/tags/W2NER/"/>
    
      <category term="NNW" scheme="https://www.yam.gift/tags/NNW/"/>
    
      <category term="THW" scheme="https://www.yam.gift/tags/THW/"/>
    
  </entry>
  
  <entry>
    <title>跨视角大脑解码</title>
    <link href="https://www.yam.gift/2022/07/02/Paper/2022-07-02-Cross-view-Brain-Decoding/"/>
    <id>https://www.yam.gift/2022/07/02/Paper/2022-07-02-Cross-view-Brain-Decoding/</id>
    <published>2022-07-02T15:00:00.000Z</published>
    <updated>2022-07-03T03:51:53.580Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2204.09564&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2204.09564] Cross-view Brain Decoding&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：跨视角的 Zero-Shot 推理和翻译是可行的。&lt;/p&gt;
&lt;p&gt;摘要：大脑如何跨多个视角捕获语义仍然是个谜团，之前的都是单视角：如（1）带目标词标签的图片（WP）；（2）使用目标词的句子（S）；（3）包含带目标词的词云（WC）以及其他语义相关的词。本文提出跨视图翻译任务，如：图像字幕（IC）、图像标签（IT）、关键字提取（KE）和句子形成（SF），在此基础上研究大脑解码。通过实验证明了跨视角 Zero-Shot 是实用的，pairwise acc 大约为 68%。此外，解码后的表征在翻译任务上的 acc 表现也不错：IC（78%）、IT（83%）、KE（83.7 %）、SF（74.5%）。得出关于大脑的认知结论：（1）高比例的视觉像素参与 IC 和 IT 任务，高比例的语言像素参与 SF 和 KE 任务；（2）在 S 视角上训练并在 WC 视角上测试的 Zero-Shot 精度优于在 WC 视角上训练和测试。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文 view 均描述为「视角」，其实类似于一种形式或模式；translation 描述为「翻译任务」，其实是从一种 view 到另一种，在本文是不同的刺激到文本。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="Cross-view" scheme="https://www.yam.gift/tags/Cross-view/"/>
    
      <category term="Brain" scheme="https://www.yam.gift/tags/Brain/"/>
    
      <category term="Brain Decoding" scheme="https://www.yam.gift/tags/Brain-Decoding/"/>
    
      <category term="Zero-Short" scheme="https://www.yam.gift/tags/Zero-Short/"/>
    
  </entry>
  
  <entry>
    <title>统一NER为词词关系分类</title>
    <link href="https://www.yam.gift/2022/06/11/Paper/2022-06-11-W2NER/"/>
    <id>https://www.yam.gift/2022/06/11/Paper/2022-06-11-W2NER/</id>
    <published>2022-06-11T15:00:00.000Z</published>
    <updated>2022-07-17T10:04:59.987Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2112.10070&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2112.10070] Unified Named Entity Recognition as Word-Word Relation Classification&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：基于词-词关系分类、可同时解决平铺、重叠和不连续 NER 的统一框架。&lt;/p&gt;
&lt;p&gt;摘要：NER 任务主要有三种类型：Flat（平铺）、overlapped（重叠或嵌套）、discontinuous（不连续），越来越多的研究致力于将它们统一起来。当前的 STOA 主要包括基于 Span 和 Seq2Seq 模型，不过它们很少关注边界，可能会导致后续的偏移。本文提出的统一方法（W2NER）是将其视为词词关系分类，为此引入两种词词关系：&lt;code&gt;NNW&lt;/code&gt;（&lt;code&gt;Next-Neighboring-Word&lt;/code&gt;）和 &lt;code&gt;THW-*&lt;/code&gt;（&lt;code&gt;Tail-Head-Word-*&lt;/code&gt;）。具体而言，构造一个 2D 的词词关系网格，然后使用多粒度 2D 卷积，以更好地细化网格表示。最后，使用一个共同预测器来推理词-词关系。效果自然是最新的 STOA。&lt;/p&gt;
&lt;p&gt;关于本文代码部分，可参考：&lt;a href=&quot;https://yam.gift/2022/07/17/Paper/2022-07-17-W2NER-Code/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;W2NER 代码&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="NER" scheme="https://www.yam.gift/tags/NER/"/>
    
      <category term="W2NER" scheme="https://www.yam.gift/tags/W2NER/"/>
    
      <category term="NNW" scheme="https://www.yam.gift/tags/NNW/"/>
    
      <category term="THW" scheme="https://www.yam.gift/tags/THW/"/>
    
      <category term="Span" scheme="https://www.yam.gift/tags/Span/"/>
    
      <category term="BIO" scheme="https://www.yam.gift/tags/BIO/"/>
    
      <category term="BIOHD" scheme="https://www.yam.gift/tags/BIOHD/"/>
    
  </entry>
  
  <entry>
    <title>预训练模型与传统方法在排序上有啥不同？</title>
    <link href="https://www.yam.gift/2022/04/23/Paper/2022-04-23-Pretrained-for-Rank/"/>
    <id>https://www.yam.gift/2022/04/23/Paper/2022-04-23-Pretrained-for-Rank/</id>
    <published>2022-04-23T15:00:00.000Z</published>
    <updated>2022-04-23T08:52:09.951Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2204.07233&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2204.07233] How Different are Pre-trained Transformers for Text Ranking?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：BM25 粗排+CE 精排，你值得拥有。&lt;/p&gt;
&lt;p&gt;摘要：近年来与传统的检索模型和反馈方法相比，大规模预训练的效果有了显著提高。不过这些结果主要是基于 &lt;a href=&quot;https://github.com/microsoft/MSMARCO-Passage-Ranking&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MS Macro/ TREC&lt;/a&gt; 设置，非常特殊，我们对模型为什么好的理解是分散的。本文在文档检索任务上分析了 BERT 的交叉编码器与传统的 BM25 ，研究两个问题：第一，它们的相似之处在哪里？深度学习方法在多大程度上包含了 BM25 的能力，性能的提升是否由于相同文档的排名更高。第二，它们的不同之处是什么？深度学习方法能否检索 BM25 漏掉的文档。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Pretrain" scheme="https://www.yam.gift/tags/Pretrain/"/>
    
      <category term="CE BERT" scheme="https://www.yam.gift/tags/CE-BERT/"/>
    
      <category term="BM25" scheme="https://www.yam.gift/tags/BM25/"/>
    
      <category term="Rank" scheme="https://www.yam.gift/tags/Rank/"/>
    
  </entry>
  
  <entry>
    <title>MarkBERT</title>
    <link href="https://www.yam.gift/2022/04/23/Paper/2022-04-23-MarkBERT/"/>
    <id>https://www.yam.gift/2022/04/23/Paper/2022-04-23-MarkBERT/</id>
    <published>2022-04-23T15:00:00.000Z</published>
    <updated>2022-04-23T10:30:17.535Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2203.06378&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2203.06378] MarkBERT: Marking Word Boundaries Improves Chinese BERT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：在 Token 中加入你感兴趣的词的边界标记。&lt;/p&gt;
&lt;p&gt;摘要：MarkBERT 不是基于词的 BERT，依然是基于字，但巧妙地将「词的边界标记」信息融入模型。这样可以统一处理任意词，无论是不是 OOV。另外，MarkBERT 还有两个额外的好处：首先，在边界标记上添加单词级别的学习目标很方便，这是对传统字符和句子级预训练任务的补充；其次，可以通过用 POS 标签特定的标记替换通用标记来轻松合并更丰富的语义。在 NER 任务上取得了 2 个点的提升，在文本分类、关键词识别、语义相似任务上也取得了更好的精度。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="BERT" scheme="https://www.yam.gift/tags/BERT/"/>
    
      <category term="NER" scheme="https://www.yam.gift/tags/NER/"/>
    
      <category term="MarkBERT" scheme="https://www.yam.gift/tags/MarkBERT/"/>
    
      <category term="RWD" scheme="https://www.yam.gift/tags/RWD/"/>
    
  </entry>
  
  <entry>
    <title>量化NLM模型的记忆力</title>
    <link href="https://www.yam.gift/2022/04/15/Paper/2022-04-15-Quantifying-Memorization-NLM/"/>
    <id>https://www.yam.gift/2022/04/15/Paper/2022-04-15-Quantifying-Memorization-NLM/</id>
    <published>2022-04-15T15:00:00.000Z</published>
    <updated>2022-04-16T12:05:51.682Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2202.07646&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2202.07646] Quantifying Memorization Across Neural Language Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：更大的模型更可能学到重复数据的特性，去重是缓解模型记忆危害的不错策略。&lt;/p&gt;
&lt;p&gt;摘要：语言模型能够记住一些训练数据，如果经过合适地提示引导，可能会生成记住的数据。这肯定不太合适，因为可能会侵犯隐私、降低效用（重复的容易记住的词往往质量比较低），并且有失公平（有些文本被记住而有些没有）。本文描述了三个对数线性关系，量化了 LM 生成记忆数据的程度。记忆会显著增加，如果增大：（1）模型的容量，（2）样本的重复次数，（3）提示文的 Token 数量。总的来说，LM 的记忆比之前认识到的更普遍，并随着模型不断增大可能变得更糟。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="PLM" scheme="https://www.yam.gift/tags/PLM/"/>
    
      <category term="NLM" scheme="https://www.yam.gift/tags/NLM/"/>
    
  </entry>
  
  <entry>
    <title>NLP预训练模型的不可能三角</title>
    <link href="https://www.yam.gift/2022/04/15/Paper/2022-04-15-Impossible-Triangle/"/>
    <id>https://www.yam.gift/2022/04/15/Paper/2022-04-15-Impossible-Triangle/</id>
    <published>2022-04-15T03:00:00.000Z</published>
    <updated>2022-04-16T03:09:16.665Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/2204.06130&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2204.06130] Impossible Triangle: What’s Next for Pre-trained Language Models?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：提出 NLP 模型的不可能三角并基于此提出未来的研究方向。&lt;/p&gt;
&lt;p&gt;摘要：本文主要描述了 PLM 的不可能三角：中等模型大小（1B以下），SOTA few-shot 能力，SOTA 微调能力。目前所有的 PLM 都缺其中一个或多个。很多注入知识蒸馏、数据增强、Prompt 的方法用以缓解这些缺失，但却在实际中带来了新的工作量。本文提供了一个未来的研究方向，将任务分解成几个关键阶段来实现不可能三角。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Impossible-Triangle" scheme="https://www.yam.gift/tags/Impossible-Triangle/"/>
    
      <category term="PLM" scheme="https://www.yam.gift/tags/PLM/"/>
    
  </entry>
  
  <entry>
    <title>Training Data is More Valuable than You Think</title>
    <link href="https://www.yam.gift/2022/04/05/Paper/2022-04-05-Retrieving-From-Training-Data/"/>
    <id>https://www.yam.gift/2022/04/05/Paper/2022-04-05-Retrieving-From-Training-Data/</id>
    <published>2022-04-05T15:00:00.000Z</published>
    <updated>2022-04-16T06:11:53.778Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/2203.08773&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2203.08773] Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/microsoft/REINA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;microsoft/REINA&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：在检索任务中训练数据在推理时也大有用处。&lt;/p&gt;
&lt;p&gt;摘要：从大规模数据中检索通常比较耗时，仅从训练数据中也能有巨大收益。具体做法是检索与输入文本最相似的训练样例，拼接后作为输入喂入模型，然后生成结果。结果在摘要、翻译、语言模型和QA上都取得了不错的效果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Summarization" scheme="https://www.yam.gift/tags/Summarization/"/>
    
      <category term="Retrieving" scheme="https://www.yam.gift/tags/Retrieving/"/>
    
      <category term="QA" scheme="https://www.yam.gift/tags/QA/"/>
    
  </entry>
  
  <entry>
    <title>句子表征综述</title>
    <link href="https://www.yam.gift/2022/03/27/NLP/2022-03-27-Sentence-Representation-Summarization/"/>
    <id>https://www.yam.gift/2022/03/27/NLP/2022-03-27-Sentence-Representation-Summarization/</id>
    <published>2022-03-27T15:30:00.000Z</published>
    <updated>2022-04-05T02:09:10.490Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;早上收到从 Google Scholar 推送的宗成庆老师团队 2019 年的一篇 Paper：《Towards Sentence-Level Brain Decoding with Distributed Representations》，看这个题目觉得挺有趣就翻开读了读。这篇 Paper 研究的核心是：从大脑激活的模式解码整个句子，即构建解码器，通过分布式表示将大脑活动与句子刺激联系起来。并比较了句子表示与高级认知功能相关的不同大脑区域的对应关系，发现&lt;strong&gt;有监督的结构化表示模型最准确地探索了人类大脑的语言图谱&lt;/strong&gt;。句子的表征 NLPer 们应该都很熟悉，那大脑的激活又是怎么弄呢？作者使用了 Nature 的一篇论文《Toward a universal decoder of linguistic meaning from brain activation》【1】中的研究成果，这篇论文主要研究从图像数据中解码语言（单词和句子）意义，结果表明，解码表示甚至可以区分语义相似的句子，并捕捉到句子之间意义关系的相似结构。这就是说，我们在看到不同的单词和句子时，大脑内部显示出不同的状态，这种状态甚至在很相似的句子之间也表现的不同。关于项目的详细情况可以查阅【2】（我没细看 :D）。&lt;/p&gt;
&lt;p&gt;宗老师这篇 Paper 正好涉及到两个我个人比较感兴趣的点：认知科学和句子表征，关于这两个方面，我之前的几篇小文都涉及过，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://yam.gift/2018/07/22/NLP/2018-07-22-NLP-and-AI/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NLP 与 AI | Yam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://yam.gift/2017/09/07/NLP/2017-09-07-Language-AI-Emotion/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;语言、AI、情感 | Yam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://yam.gift/2020/12/12/NLP/2020-12-12-NLP-Representation-History-Future/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;NLP 表征的历史与未来 | Yam&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;抛开认知部分不谈，句子表征也是一个很有意思的方向，因为相比「词」，「句子」才是基本的『语义单位』。恰巧这篇 Paper 中也提到了不少句子表征的方法，正好一起来个梳理，顺便表达一点自己的脑洞。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Thinking" scheme="https://www.yam.gift/categories/Thinking/"/>
    
    
      <category term="AI" scheme="https://www.yam.gift/tags/AI/"/>
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Sentence Representation" scheme="https://www.yam.gift/tags/Sentence-Representation/"/>
    
  </entry>
  
  <entry>
    <title>T5：Exploring the limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
    <link href="https://www.yam.gift/2022/03/05/Paper/2022-03-05-T5/"/>
    <id>https://www.yam.gift/2022/03/05/Paper/2022-03-05-T5/</id>
    <published>2022-03-05T15:00:00.000Z</published>
    <updated>2022-03-05T12:43:59.765Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/1910.10683&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[1910.10683] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/google-research/text-to-text-transfer-transformer&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;google-research/text-to-text-transfer-transformer: Code for the paper “Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;一句话概述：把所有 NLP 任务统一成 Text-to-Text 格式使用 Transformer 统一处理。&lt;/p&gt;
&lt;p&gt;摘要：迁移学习在 NLP 领域已经是最有效的方法，本文引入了统一的文本处理框架——将所有文本问题统一成 Text-to-Text 的格式。为了验证效果，构建了 C4 数据集（Colossal Clean Crawled Cropus），结果发现取得了很好的效果。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Transformer" scheme="https://www.yam.gift/tags/Transformer/"/>
    
      <category term="T5" scheme="https://www.yam.gift/tags/T5/"/>
    
      <category term="MTL" scheme="https://www.yam.gift/tags/MTL/"/>
    
      <category term="C4" scheme="https://www.yam.gift/tags/C4/"/>
    
  </entry>
  
  <entry>
    <title>ExT5：Towards Extreme Multi-Task Scaling for Transfer Learning</title>
    <link href="https://www.yam.gift/2022/02/19/Paper/2022-02-19-ExT5/"/>
    <id>https://www.yam.gift/2022/02/19/Paper/2022-02-19-ExT5/</id>
    <published>2022-02-19T15:00:00.000Z</published>
    <updated>2022-02-20T12:54:17.777Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/2111.10952&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2111.10952] ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：T5&lt;/p&gt;
&lt;p&gt;一句话概述：任务数量很多时，不妨试试 MTL 预训练。&lt;/p&gt;
&lt;p&gt;摘要：尽管多任务和迁移学习取得了巨大成功，但很少有工作研究预训练期间扩大任务数量的效果。本文提出 ExMIX（Extreme Mixture）：一个包含 107 个有监督任务的跨领域大规模任务集合。并借此研究了迄今为止最大规模的多任务预训练效果，分析常见任务族之间的协同训练迁移。结果显示，为多任务预训练手动策划一组理想的任务并不简单，而且多任务扩展本身可以极大地改进模型。最后，提出 ExT5：使用自监督跨度去噪和监督 ExMIX 的多任务目标预训练模型，在多个数据集上超过了 T5。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="ExT5" scheme="https://www.yam.gift/tags/ExT5/"/>
    
      <category term="T5" scheme="https://www.yam.gift/tags/T5/"/>
    
      <category term="MTL" scheme="https://www.yam.gift/tags/MTL/"/>
    
  </entry>
  
  <entry>
    <title>《舞狮少年》观后——信念、文化与希望</title>
    <link href="https://www.yam.gift/2021/12/26/Diary/2021-12-25-Lion-Dance/"/>
    <id>https://www.yam.gift/2021/12/26/Diary/2021-12-25-Lion-Dance/</id>
    <published>2021-12-26T15:00:00.000Z</published>
    <updated>2021-12-26T17:05:07.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;疫情一波又一波，感觉已经很久没有出去过了，周六晚上舒璇说明天一起出去看个电影吧，好久没有活动了，最近正好上映了一部口碑很不错的片子。我好奇一问：“啥电影啊？”答：“舞狮少年”。我一想，哎，这不是昨晚看某个 UP 主提到过的影片么，说看起来像是鸡汤片。对鸡汤我一向是不喜欢的，可能是以前喝太多了，有点腻上头了。不过最后，当然是毫无异议地来到了电影院，我其实有点担心自己会睡着。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Thinking" scheme="https://www.yam.gift/categories/Thinking/"/>
    
    
      <category term="Diary" scheme="https://www.yam.gift/tags/Diary/"/>
    
      <category term="Culture" scheme="https://www.yam.gift/tags/Culture/"/>
    
      <category term="Faith" scheme="https://www.yam.gift/tags/Faith/"/>
    
      <category term="Hope" scheme="https://www.yam.gift/tags/Hope/"/>
    
  </entry>
  
  <entry>
    <title>Multitask Prompted Training Enables Zero-shot Task Generalization</title>
    <link href="https://www.yam.gift/2021/12/25/Paper/2021-12-25-MLT-Promote/"/>
    <id>https://www.yam.gift/2021/12/25/Paper/2021-12-25-MLT-Promote/</id>
    <published>2021-12-25T15:00:00.000Z</published>
    <updated>2021-12-26T12:58:56.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;一句话描述：多任务 Prompt 可以明确影响 Zero-shot 学习。&lt;/p&gt;
&lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/2110.08207&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2110.08207] Multitask Prompted Training Enables Zero-Shot Task Generalization&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：&lt;a href=&quot;https://github.com/bigscience-workshop/promptsource/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;bigscience-workshop/promptsource: Toolkit for collecting and applying prompts&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;摘要：大语言模型显示出可观的 Zero-shot 泛化能力，被假设成是语言模型中多任务训练暗含的结果，所以这个能力能不能体现的直接点？本文使用一大堆有监督数据集，每个又有多个不同自然语言的 prompt，通过微调一个预训练的 Encoder-Decoder 模型，取得不错的 Zero-shot 性能。真可谓是大数据集、大 prompt 出奇迹。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="Multitask" scheme="https://www.yam.gift/tags/Multitask/"/>
    
      <category term="Promote" scheme="https://www.yam.gift/tags/Promote/"/>
    
      <category term="Zero-shot" scheme="https://www.yam.gift/tags/Zero-shot/"/>
    
  </entry>
  
  <entry>
    <title>虚拟网络指南</title>
    <link href="https://www.yam.gift/2021/12/19/Net/2021-12-19-VirtualNetwork/"/>
    <id>https://www.yam.gift/2021/12/19/Net/2021-12-19-VirtualNetwork/</id>
    <published>2021-12-19T15:00:00.000Z</published>
    <updated>2021-12-26T15:28:19.404Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;问题的研究总是源于现实，这不，一直对虚拟机的几种网络懵懵懂懂，直到有个需求冒出来，这才想办法（有机会）一把撸掉。&lt;/p&gt;
&lt;p&gt;业务背景描述：一台 Win10 的主机，跟了我很多年的 ThinkPad，只有 4 核 4G；由于工作、生活各种需要，里面用 VirtualBox 装了个 Ubuntu18 的虚拟机。平时写代码，跑个实验啥的就都在虚拟机上。突然需要在局域网多台终端上能够访问到虚拟机中的某个服务，自然少不了要一番配置，研究一天后终于把几个主流模式差不多搞清楚了，特记录如下。当然，尚有诸多细节留待日后继续研究。&lt;/p&gt;
&lt;p&gt;先把官方文档的一张表放这里：&lt;/p&gt;
&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Mode&lt;/th&gt;
&lt;th&gt;VM→Host&lt;/th&gt;
&lt;th&gt;VM←Host&lt;/th&gt;
&lt;th&gt;VM1←→VM2&lt;/th&gt;
&lt;th&gt;VM→Net/LAN&lt;/th&gt;
&lt;th&gt;VM←Net/LAN&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Host-only&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;—（共享网卡后+）&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Internal&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;td&gt;—&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bridged&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NAT&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;端口转发&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;端口转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NATservice&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;端口转发&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;+&lt;/td&gt;
&lt;td&gt;端口转发&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;表格来自：&lt;a href=&quot;https://www.virtualbox.org/manual/ch06.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.virtualbox.org/manual/ch06.html&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://www.yam.gift/categories/Coding/"/>
    
    
      <category term="CS" scheme="https://www.yam.gift/tags/CS/"/>
    
      <category term="Network" scheme="https://www.yam.gift/tags/Network/"/>
    
      <category term="Virtual Network" scheme="https://www.yam.gift/tags/Virtual-Network/"/>
    
      <category term="NAT" scheme="https://www.yam.gift/tags/NAT/"/>
    
      <category term="Host-only" scheme="https://www.yam.gift/tags/Host-only/"/>
    
      <category term="Bridge" scheme="https://www.yam.gift/tags/Bridge/"/>
    
  </entry>
  
  <entry>
    <title>Pretrain, Prompt and Predict, A Systematic Survey of Prompting Methods in NLP</title>
    <link href="https://www.yam.gift/2021/12/04/Paper/2021-12-04-Prompt/"/>
    <id>https://www.yam.gift/2021/12/04/Paper/2021-12-04-Prompt/</id>
    <published>2021-12-04T15:00:00.000Z</published>
    <updated>2021-12-11T12:18:06.000Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/2107.13586&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2107.13586] Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：无&lt;/p&gt;
&lt;p&gt;一句话概述：想办法在输入和标签之间搭一座桥。&lt;/p&gt;
&lt;p&gt;摘要：与传统有监督学习不同的是，基于 Prompt 的学习基于语言模型直接对文本的概率进行建模。具体来说，为了使用这些模型执行预测任务，使用模板将原始输入 x 修改为具有一些未填充槽的文本字符串提示 x’，然后使用语言模型对未填充信息进行概率填充以获得最终字符串 x^，从中可以导出最终输出 y。这个框架强大且有吸引力的原因有很多：它允许语言模型在大量原始文本上进行预训练，并且通过定义一个新的 Prompt 函数，模型能够执行少样本甚至零样本学习，适应很少或没有标注数据的新场景。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Prompt" scheme="https://www.yam.gift/tags/Prompt/"/>
    
  </entry>
  
  <entry>
    <title>Data Augmentation Approaches in Natural Language Processing：A Survey</title>
    <link href="https://www.yam.gift/2021/11/28/Paper/2021-11-28-DataAugmentation/"/>
    <id>https://www.yam.gift/2021/11/28/Paper/2021-11-28-DataAugmentation/</id>
    <published>2021-11-28T15:00:00.000Z</published>
    <updated>2021-11-28T14:49:44.387Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;论文：&lt;a href=&quot;https://arxiv.org/abs/2110.01852&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2110.01852] Data Augmentation Approaches in Natural Language Processing: A Survey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code：无&lt;/p&gt;
&lt;p&gt;一句话概述：全面和结构化的数据增强文献综述。&lt;/p&gt;
&lt;p&gt;摘要：DA 缓解了深度学习中数据不足的场景，在图像领域首先得到广泛使用，进而延伸到 NLP 领域，并在许多任务上取得效果。一个主要的方向是增加训练数据的多样性，从而提高模型泛化能力。本文将 DA 方法基于增强数据的多样性分成三类：释义、噪声和采样，分别进行详细分析，另外也介绍了它们在 NLP 任务中的应用和挑战。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Feeling" scheme="https://www.yam.gift/categories/Feeling/"/>
    
    
      <category term="NLP" scheme="https://www.yam.gift/tags/NLP/"/>
    
      <category term="Data Augmentation" scheme="https://www.yam.gift/tags/Data-Augmentation/"/>
    
      <category term="DA" scheme="https://www.yam.gift/tags/DA/"/>
    
      <category term="Data Enhancement" scheme="https://www.yam.gift/tags/Data-Enhancement/"/>
    
  </entry>
  
</feed>

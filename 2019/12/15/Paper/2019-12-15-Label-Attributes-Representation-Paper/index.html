<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <meta name="description" content="AI | NLP | 人工智能 | 哲学 | 自然语言处理 | 机器学习" />
  

  
  
  
  
  
  <title>Few-Shot Charge Prediction with Discriminative Legal Attributes 论文笔记 | Yam</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Paper: coling2018_attribute.pdf code: thunlp/attribute_charge 核心思想：基于类别属性的注意力机制共同学习属性感知和无属性的文本表示。 这是 COLING2018 上的一篇老论文了，最近因为一些事情正好遇上，当时大概看了一下就发现这篇文章正好解决了我之前在做多分类任务时没有解决的问题。所以拿来记录一下，顺便研究下代码。">
<meta name="keywords" content="NLP,Few-Shot,Imbalance Data,Confusing Labels">
<meta property="og:type" content="article">
<meta property="og:title" content="Few-Shot Charge Prediction with Discriminative Legal Attributes 论文笔记">
<meta property="og:url" content="https://www.yam.gift/2019/12/15/Paper/2019-12-15-Label-Attributes-Representation-Paper/index.html">
<meta property="og:site_name" content="Yam">
<meta property="og:description" content="Paper: coling2018_attribute.pdf code: thunlp/attribute_charge 核心思想：基于类别属性的注意力机制共同学习属性感知和无属性的文本表示。 这是 COLING2018 上的一篇老论文了，最近因为一些事情正好遇上，当时大概看了一下就发现这篇文章正好解决了我之前在做多分类任务时没有解决的问题。所以拿来记录一下，顺便研究下代码。">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-1.jpeg">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-2.jpeg">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-3.jpeg">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-4.jpeg">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-5.jpeg">
<meta property="og:image" content="http://qnimg.lovevivian.cn/paper-shot-charge-prediction-6.jpeg">
<meta property="og:updated_time" content="2020-05-03T03:30:51.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Few-Shot Charge Prediction with Discriminative Legal Attributes 论文笔记">
<meta name="twitter:description" content="Paper: coling2018_attribute.pdf code: thunlp/attribute_charge 核心思想：基于类别属性的注意力机制共同学习属性感知和无属性的文本表示。 这是 COLING2018 上的一篇老论文了，最近因为一些事情正好遇上，当时大概看了一下就发现这篇文章正好解决了我之前在做多分类任务时没有解决的问题。所以拿来记录一下，顺便研究下代码。">
<meta name="twitter:image" content="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-1.jpeg">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  

  
  <!-- baidu webmaster push -->
<link rel="alternate" href="/atom.xml" title="Yam" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>
<body class="home blog custom-background custom-font-enabled single-author">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="Yam" rel="home">Yam</a>
      </h1>
      
        <h2 class="site-description">
          <a href="/" id="subtitle">Feeling, Coding, Thinking</a>
        </h2>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/series/">Series</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives/">Archives</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/about/">About</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="https://github.com/hscspring">Projects</a></li>
                
                </ul>
            </div>
    </nav>
</header>
      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main"><article id="post-Paper/2019-12-15-Label-Attributes-Representation-Paper" class="post-Paper/2019-12-15-Label-Attributes-Representation-Paper post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title article-title">
      Few-Shot Charge Prediction with Discriminative Legal Attributes 论文笔记
    </h1>
  

        
        <!-- <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="https://www.yam.gift/2019/12/15/Paper/2019-12-15-Label-Attributes-Representation-Paper/" data-id="ckplb0cde00bs0abzl3j6xvys" class="leave-reply bdsharebuttonbox" data-cmd="more">undefined</a>
        </div> --><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
            <!-- Table of Contents -->
              
        <p>Paper: <a href="http://nlp.csai.tsinghua.edu.cn/~tcc/publications/coling2018_attribute.pdf" target="_blank" rel="noopener">coling2018_attribute.pdf</a></p>
<p>code: <a href="https://github.com/thunlp/attribute_charge" target="_blank" rel="noopener">thunlp/attribute_charge</a></p>
<p>核心思想：基于类别属性的注意力机制共同学习属性感知和无属性的文本表示。</p>
<p>这是 COLING2018 上的一篇老论文了，最近因为一些事情正好遇上，当时大概看了一下就发现这篇文章正好解决了我之前在做多分类<a href="https://github.com/hscspring/Multi-Label-Text-Classification-for-Chinese#others" target="_blank" rel="noopener">任务</a>时没有解决的问题。所以拿来记录一下，顺便研究下代码。</p>
<a id="more"></a>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>本文主要解决罪名预测（根据刑事法律文书中的案情描述和事实部分，预测被告人被判的罪名）中的两个问题：</p>
<ul>
<li>数据不平衡问题：有些罪名的 case 太少</li>
<li>标签相似的问题：有些罪名意思过于接近</li>
</ul>
<p>文章通过提取罪名相关属性作为额外特征，不仅为 case 少的罪名类别提供了信息，同时还可以作为鉴别相似标签的有效信号。结果在 few-shot 场景下比 baseline 取得 50% 的提升。</p>
<p>看到这里当时就有两个反应：卧槽，为啥这么简单我没想到？卧槽，为啥这么简单的方法效果居然这么好？</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>传统的做法是人工设计特征，包括文本相关（字、词、短语）和属性特征相关（日期，位置，条款，类型），目前基本都是用深度学习的方法在做了。</p>
<p>不过依然有两个主要挑战：</p>
<ul>
<li>Few-Shot Charges：实际场景中，最多的 10 种罪名占了 78.1%，最少的 50 种罪名仅占不到 0.5% 而且大部分就 10 个左右的案例。传统的方法一般忽略少的，深度学习需要一定量的训练样本。所以，这个问题成为决定一个系统鲁棒性和有效性的关键。</li>
<li>Confusing Charges：比如（盗窃，抢劫），（挪用资金，挪用公款），它们的定义仅在验证特定行为时有所不同，对应案例中的条件常常非常相似。</li>
</ul>
<p>为了解决这两个问题，本文建议考虑具有区别罪名的法律属性，并将这些属性作为犯罪事实描述和罪名之间的映射。具体而言，选中 10 个有代表属性的罪名，然后进行低成本类别级构建：对每个罪名，注释每个属性的值（是，否或不可用）。</p>
<p>有了属性注释后，本文提出一个多任务学习框架来同时预测每个案例的属性和罪名。在模型中，使用属性注意力机制来捕获与特定属性相关的关键事实信息。之后，将这些属性感知与无属性事实表征（文本表征）结合起来，预测最终的罪名。</p>
<p>这样做的两个原因：</p>
<ul>
<li>这些属性可以提供有关如何区分相似罪名的明确知识。</li>
<li>所有罪名共享这些属性，知识可以从高频罪名转向低频罪名。</li>
</ul>
<p>本文的三个主要贡献：</p>
<ul>
<li>首先专注于 Few-Shot Charges 和 Confusing Charges。</li>
<li>提出了一种新颖的多任务学习框架，以共同推断案件的属性和指控。采用注意力机制学习属性感知的事实表示。</li>
<li>在真实数据集上结果优于其他基准，在 few-short 罪名上的提升超过 50%。</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Zero-Shot-Classification"><a href="#Zero-Shot-Classification" class="headerlink" title="Zero-Shot Classification"></a>Zero-Shot Classification</h3><p>与计算视觉中的 Zero-Shot 相关。有许多基于属性的模型，属性在不同类别间共享并提供中间表示。</p>
<ul>
<li>Lampert et al. (2014) 提出了 direct attribute prediction 和 indirect attribute prediction，并提出可以预训练，当需要寻找新的合适的对象类别时就不用再训练的属性分类器。</li>
<li>Akata et al. (2013) 提出将基于属性的分类任务转为标签 embedding 任务。</li>
<li>Jayaraman, Grauman (2014) 引入随机森林方法，强调了未知类别属性预测的不可靠性。</li>
</ul>
<p>除了属性外，还可以引入其他信息：</p>
<ul>
<li>Elhoseiny et al. (2014) 使用标签的文本描述在文本特征和视觉特征之间传递知识。</li>
<li>Zero-Shot 除了用在 object recognition 外，还被用于 activity recognition 和 event recognition</li>
</ul>
<h3 id="Charge-Prediction"><a href="#Charge-Prediction" class="headerlink" title="Charge Prediction"></a>Charge Prediction</h3><p>法律领域一直致力于自动裁决。</p>
<ul>
<li>Kort (1957) 使用定量方法计算事实元素的数值预测。</li>
<li>Nagel (1963) 利用相关性分析对重新分配案件进行预测。</li>
<li>Keown (1980) 引入数学模型，如线性模型和最近邻。</li>
</ul>
<p>这些模型通常限于标签少的小型数据集。</p>
<p>在机器学习兴起时，问题转化为文本分类，通常需要从案例中提取特征。</p>
<ul>
<li>Lin 等 (2012) 提取 21 个法律因素标签分类。</li>
<li>Mackaay 和 Robillard (1974) 提取了 Ngram 和通过语义相似 Ngram 聚类得到的主题作为特征。</li>
<li>Sulea 等 (2017) 提出了基于 SVM 继承的系统，使用案例描述，案例的裁定和时间跨度作为输入。</li>
</ul>
<p>不过这些方法只能提取在大数据集上难以收集的浅层语义表征或手动标签，而且，常规模型无法捕捉相似犯罪之间的细微差别。</p>
<p>随着深度学习的兴起，Luo et al. (2017) 提出了一个分层注意力网络同时预测罪名并提取相关文章。</p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Discriminative-Charge-Attributes"><a href="#Discriminative-Charge-Attributes" class="headerlink" title="Discriminative Charge Attributes"></a>Discriminative Charge Attributes</h3><p>为所有罪名引入了 10 个判别属性，对每个（罪名，属性）对，可以标记为是，否或不可用）。比如，故意杀人罪的指控在故意犯罪上标记为 “否”，在死亡时标记为 “是”，在国家机关标记为 “不适用”。对特定属性，特定案件的标签和相应罪名的标签应相同或不冲突。在实践中，手动标记了 149 种不同罪名的属性，然后为每个案例分配与其相应罪名相同的属性。<img src="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-1.jpeg" alt=""></p>
<h3 id="Formalizations"><a href="#Formalizations" class="headerlink" title="Formalizations"></a>Formalizations</h3><p><img src="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-2.jpeg" alt=""></p>
<h4 id="Charge-Prediction-1"><a href="#Charge-Prediction-1" class="headerlink" title="Charge Prediction"></a>Charge Prediction</h4><p>给定犯罪事实文本，预测一个罪名</p>
<h4 id="Attributes-Prediction"><a href="#Attributes-Prediction" class="headerlink" title="Attributes Prediction"></a>Attributes Prediction</h4><p>二分类任务，给定犯罪事实文本，预测每个属性的分类</p>
<h4 id="Fact-Encoder"><a href="#Fact-Encoder" class="headerlink" title="Fact Encoder"></a>Fact Encoder</h4><p>LSTM + Max-Pooling 获得无属性文本表征</p>
<script type="math/tex; mode=display">
e_{i}=\max \left(\mathbf{h}_{1, i}, \cdots, \mathbf{h}_{n, i}\right), \forall i \in[1, s]</script><p>s 是 hidden states 的维度。n 是 time step。也就是取了每个 hidden state 中的最大值提出来重新组成一个向量作为句子的表征。</p>
<h4 id="Attentive-Attribute-Predictor"><a href="#Attentive-Attribute-Predictor" class="headerlink" title="Attentive Attribute Predictor"></a>Attentive Attribute Predictor</h4><p>采用注意力机制从犯罪事实文本中选择相关信息并生成属性感知的事实表示。</p>
<p>Step1: 输入为 hidden states 序列：<code>h = {h1, ..., hn}</code></p>
<p>Step 2: 然后计算所有属性的 attention weights <code>a = {a1, ..., ak}</code>，<code>ai = [ai1,...ain]</code>：</p>
<script type="math/tex; mode=display">
a_{i, j}=\frac{\exp \left(\tanh \left(\mathbf{W}^{a} \mathbf{h}_{j}\right)^{T} \mathbf{u}_{i}\right)}{\sum_{t} \exp \left(\tanh \left(\mathbf{W}^{a} \mathbf{h}_{t}\right)^{T} \mathbf{u}_{i}\right)}</script><p>ui 是第 i 个属性的上下文向量，用于计算元素对属性的信息程度。Wα 是所有属性共享的权重矩阵。</p>
<p>Step3: 然后得到属性感知的表示：<code>g = {g1, ..., gk}</code>，<code>gi = Σt ait ht</code></p>
<p>Step4: 最后用 g + softmax 获得 p 的预测结果：</p>
<script type="math/tex; mode=display">
\begin{array}{l}{\mathbf{z}_{i}=\operatorname{softmax}\left(\mathbf{W}_{i}^{p} \mathbf{g}_{i}+\mathbf{b}_{i}^{p}\right)} \\ {p_{i}=\arg \max \left(\mathbf{z}_{i}\right)}\end{array}</script><h4 id="Output-Layer"><a href="#Output-Layer" class="headerlink" title="Output Layer"></a>Output Layer</h4><p>属性无关 + 属性感知表示预测最终的罪名:</p>
<script type="math/tex; mode=display">
\begin{aligned} \mathbf{r} &=\frac{\sum_{i} \mathbf{g}_{\mathbf{i}}}{k} \\ \mathbf{v} &=\mathbf{e} \oplus \mathbf{r} \\ y &=\operatorname{softmax}\left(\mathbf{W}^{y} \mathbf{v}+\mathbf{b}^{y}\right) \end{aligned}</script><h4 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h4><p>包括两部分</p>
<p>Part1: 最小化预测罪名和真实罪名分布的交叉熵（C 是罪名总数）</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text {charge}}=-\sum_{i=1}^{C} y_{i} \cdot \log \left(\hat{y}_{i}\right)</script><p>Part2: 最小化每个属性预测分布和真实分布的交叉熵（求和是或否的 loss）</p>
<script type="math/tex; mode=display">
\mathcal{L}_{a t t r}=-\sum_{i=1}^{k} I_{i} \sum_{j=1}^{2} z_{i j} \cdot \log \left(\hat{z}_{i j}\right)</script><p><code>Ii</code> 指示 label 是 <code>yes/no (Ii=1)</code> 还是 NA（<code>Ii=0</code>)</p>
<p>最终的 loss function（α 是超参数）：</p>
<script type="math/tex; mode=display">
\mathcal{L}=\mathcal{L}_{c h a r g e}+\alpha \cdot \mathcal{L}_{a t t r}</script><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Dataset-Construction"><a href="#Dataset-Construction" class="headerlink" title="Dataset Construction"></a>Dataset Construction</h3><p>数据来源：<a href="http://wenshu.court.gov.cn/" target="_blank" rel="noopener">中国判决文书网</a></p>
<p>简单起见，将多个罪名的调整为一个罪名；同时为了检查模型在 few-shot 任务中的表现，将罪名调成为 149 个完全不同的（每个罪名至少包含 10 个案例）。</p>
<p>随机选择了 40 万案例构建了三个不同量级的数据集，它们包含的罪名相同，只是数量不同。</p>
<h3 id="Attribute-Selection-and-Annotation"><a href="#Attribute-Selection-and-Annotation" class="headerlink" title="Attribute Selection and Annotation"></a>Attribute Selection and Annotation</h3><p>如何选择属性呢？</p>
<ul>
<li>训练一个基于 LSTM 的罪名预测模型，在验证集上得到预测结果的混淆矩阵。</li>
<li>筛选出相似罪名（标签相似）对，专家从中定义出 10 个能狗区分这些相似罪名的、有代表性的属性。</li>
<li>使用这 10 个属性对所有的罪名低成本标注，所谓的低成本意思是只对 149 个罪名手动标注，而不是对所有的案例进行标注。</li>
</ul>
<blockquote>
<p>全文最经典的部分了。很聪明、优雅的做法。</p>
</blockquote>
<h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><p>多个文本分类模型 + 一个罪名预测模型：</p>
<ul>
<li>TFIDF + SVM：TFIDF 提取特征</li>
<li>CNN</li>
<li>LSTM</li>
<li>Fact-Law Attention Model: Luo et al. (2017)</li>
</ul>
<h3 id="Experiment-Settings-and-Evaluation-Metrics"><a href="#Experiment-Settings-and-Evaluation-Metrics" class="headerlink" title="Experiment Settings and Evaluation Metrics"></a>Experiment Settings and Evaluation Metrics</h3><ul>
<li>max sequence length: 500</li>
<li>TFIDF feature size: 2000</li>
<li>Skip-Gram pre-train word embeddings (size 100)</li>
<li>LSTM hidden state size: 100</li>
<li>CNN filter (2, 3, 4, 5), filter size 25</li>
<li>α = 1</li>
<li>Adam</li>
<li>lr = 0.001</li>
<li>dropout = 0.5</li>
<li>batch size 64</li>
<li>Macro-F1</li>
</ul>
<h3 id="Results-and-Analysis"><a href="#Results-and-Analysis" class="headerlink" title="Results and Analysis"></a>Results and Analysis</h3><p><img src="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-3.jpeg" alt=""></p>
<p>Few-Shot 任务的结果：（Low，≤ 10；High，&gt; 100）</p>
<p><img src="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-4.jpeg" alt=""></p>
<h3 id="Ablation-Test"><a href="#Ablation-Test" class="headerlink" title="Ablation Test"></a>Ablation Test</h3><ul>
<li>取消注意力机制时，对每个属性，将注意力机制替换为全连接层。</li>
<li>取消属性感知表示时，退化为基于 LSTM 的典型多任务学习。</li>
</ul>
<p><img src="http://qnimg.lovevivian.cn/paper-few-shot-charge-prediction-5.jpeg" alt=""></p>
<h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><blockquote>
<p>江苏省南京市江宁区人民检察院指控，2013年4月2109时许， 被告人朱某在南京市江宁区横溪街道UNK社区美尚家具厂门前 ,因驾车问题与于某甲发生争执，后朱某纠集他人至美尚家 具厂车间内，持铁棍、斧子等工具对于某甲实施<strong>殴打，被害 人尤某在帮助于</strong>某甲抵挡时被砍伤，UNK某右侧顶骨骨折等 损伤经南京市公安局江宁分局法医鉴定，被害人尤某的损伤程度为轻伤</p>
</blockquote>
<p>这个案件被判为故意伤害罪，故意伤害罪和骚扰是一对相似类别，都和暴力有关。一个重要的区别就是故意伤害罪有 “身体伤害” 的特征。</p>
<p>所以 Physical Injury 这个属性在这里一定是非常重要的，事实上模型也正确预测了 Physical Injury 的 label 是 yes，最终的罪名也预测为 “故意伤害罪”，相反，LSTM-200 则把结果预测为 “骚扰”。</p>
<p>从下面的注意力热力图也可以看出，注意力机制能够捕获当前属性相关的关键模式和语义。</p>
<p><img src="http://qnimg.lovevivian.cn/paper-shot-charge-prediction-6.jpeg" alt=""></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>为解决 Few-Shot 和标签相似问题，引入了判别法律属性，提出了基于属性的多任务学习模型。具体来说，模型通过利用基于属性的注意力机制来共同学习无属性和属性感知的事实表示。进一步的探索方向包括：更复杂的案件判断（如多标签）和更复杂的罪名属性。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2019/12/15/Paper/2019-12-15-Label-Attributes-Representation-Paper/">
    <time datetime="2019-12-15T11:00:00.000Z" class="entry-date">
        2019-12-15
    </time>
</a>
    
  <span class="article-delim">&#8226;</span>
  <div class="article-category">
  <a class="article-category-link" href="/categories/Feeling/">Feeling</a>
  </div>

    
  <span class="article-delim">&#8226;</span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Confusing-Labels/">Confusing Labels</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Few-Shot/">Few-Shot</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Imbalance-Data/">Imbalance Data</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li></ul>

    </footer>
</article>


    
<nav class="nav-single">
    <h3 class="assistive-text">文章导航</h3>
    
        <span class="nav-previous"><a href="/2019/12/15/DSA/Coding-Review2/2019-12-15-CR2-Ch3/" rel="prev"><span class="meta-nav">←</span> 剑指 Offer2（Python 版）解析（Ch3）</a></span>
    
    
        <span class="nav-next"><a href="/2019/12/11/NLP/KG/2019-12-11-Relationship-Extraction/" rel="next">关系提取简述 <span class="meta-nav">→</span></a></span>
    
</nav><!-- .nav-single -->







<div class="bdsharebuttonbox"><a href="#" class="bds_more" data-cmd="more"></a><a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a><a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a><a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a><a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a><a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a><a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a><a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a><a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a></div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{},"image":{"viewList":["fbook","twi","linkedin","qzone","tsina","douban","weixin","evernotecn"],"viewText":"分享到：","viewSize":"16"}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?'];</script>

<section id="comment">
  <!-- 评论代码 -->
  <div id="gitalk-container"></div>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
  <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
  <script>
  const gitalk = new Gitalk({
    clientID: '0eb512031083d6e7edfb',
    clientSecret: 'e830808995dd813ca26fed50573760963457da37',
    repo: 'hscspring.github.io',
    owner: 'hscspring',
    admin: ['hscspring'],
    id: md5(location.pathname),
    distractionFreeMode: false
  })
  gitalk.render('gitalk-container')
  </script>
  <!-- 评论代码已完成 -->
</section>

</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    
  <aside class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-content">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Coding/">Coding</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feeling/">Feeling</a><span class="category-list-count">88</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Thinking/">Thinking</a><span class="category-list-count">18</span></li></ul>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Music</h3>
    <div class="widget-content">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=541131&auto=0&height=66"></iframe>
      <!-- 评论代码 -->
      <!-- <audio src="http://qnimg.lovevivian.cn/miss.mp3" controls="controls"
             style="width:100%">
        您的浏览器不支持 audio 标签。
      </audio> -->
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-content tagcloud">
      <a href="/tags/AE/" style="font-size: 10px;">AE</a> <a href="/tags/AI/" style="font-size: 19.09px;">AI</a> <a href="/tags/ALBERT/" style="font-size: 10px;">ALBERT</a> <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/AUC/" style="font-size: 10px;">AUC</a> <a href="/tags/Accuracy/" style="font-size: 10px;">Accuracy</a> <a href="/tags/Activation/" style="font-size: 10px;">Activation</a> <a href="/tags/Algorithm/" style="font-size: 13.64px;">Algorithm</a> <a href="/tags/Array/" style="font-size: 10px;">Array</a> <a href="/tags/Arrow/" style="font-size: 10px;">Arrow</a> <a href="/tags/Attention/" style="font-size: 12.73px;">Attention</a> <a href="/tags/Automatic-Speech-Processing/" style="font-size: 10px;">Automatic Speech Processing</a> <a href="/tags/Automation/" style="font-size: 10px;">Automation</a> <a href="/tags/BERT/" style="font-size: 13.64px;">BERT</a> <a href="/tags/BPE/" style="font-size: 10px;">BPE</a> <a href="/tags/Backtracking/" style="font-size: 10px;">Backtracking</a> <a href="/tags/Backward/" style="font-size: 10px;">Backward</a> <a href="/tags/Bahdanau-Attention/" style="font-size: 10px;">Bahdanau Attention</a> <a href="/tags/Bart/" style="font-size: 10px;">Bart</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/Beam-Search/" style="font-size: 10px;">Beam Search</a> <a href="/tags/Bert/" style="font-size: 14.55px;">Bert</a> <a href="/tags/Bert-Flow/" style="font-size: 10px;">Bert-Flow</a> <a href="/tags/Bi-LSTM/" style="font-size: 10px;">Bi-LSTM</a> <a href="/tags/Biasing/" style="font-size: 10px;">Biasing</a> <a href="/tags/Binary-Search/" style="font-size: 11.82px;">Binary Search</a> <a href="/tags/Blending/" style="font-size: 10px;">Blending</a> <a href="/tags/Business/" style="font-size: 11.82px;">Business</a> <a href="/tags/C/" style="font-size: 10.91px;">C</a> <a href="/tags/CCG/" style="font-size: 10.91px;">CCG</a> <a href="/tags/CFG/" style="font-size: 10px;">CFG</a> <a href="/tags/CKY/" style="font-size: 10px;">CKY</a> <a href="/tags/CNN/" style="font-size: 10px;">CNN</a> <a href="/tags/CRF/" style="font-size: 10px;">CRF</a> <a href="/tags/CYK/" style="font-size: 10px;">CYK</a> <a href="/tags/Calculus/" style="font-size: 10px;">Calculus</a> <a href="/tags/Camera/" style="font-size: 10px;">Camera</a> <a href="/tags/Catalan/" style="font-size: 10px;">Catalan</a> <a href="/tags/ChatBot/" style="font-size: 10px;">ChatBot</a> <a href="/tags/Chi2/" style="font-size: 10px;">Chi2</a> <a href="/tags/Chunking/" style="font-size: 10px;">Chunking</a> <a href="/tags/Classification/" style="font-size: 10.91px;">Classification</a> <a href="/tags/Cognition/" style="font-size: 10.91px;">Cognition</a> <a href="/tags/Collaborative-Filtering/" style="font-size: 10px;">Collaborative Filtering</a> <a href="/tags/Collins-Parser/" style="font-size: 10px;">Collins Parser</a> <a href="/tags/Computational-Linguistics/" style="font-size: 10px;">Computational Linguistics</a> <a href="/tags/Computer/" style="font-size: 10px;">Computer</a> <a href="/tags/Computer-Science/" style="font-size: 12.73px;">Computer Science</a> <a href="/tags/Confusing-Labels/" style="font-size: 10px;">Confusing Labels</a> <a href="/tags/Context-Free-Grammars/" style="font-size: 10px;">Context-Free Grammars</a> <a href="/tags/Contrastive-Learning/" style="font-size: 10px;">Contrastive-Learning</a> <a href="/tags/Coordinate-Ascent/" style="font-size: 10px;">Coordinate Ascent</a> <a href="/tags/Cosine/" style="font-size: 10.91px;">Cosine</a> <a href="/tags/Cosine-Similarity/" style="font-size: 10px;">Cosine Similarity</a> <a href="/tags/Cross-Entropy/" style="font-size: 10px;">Cross Entropy</a> <a href="/tags/Cross-brackets/" style="font-size: 10px;">Cross-brackets</a> <a href="/tags/Ctrl/" style="font-size: 10px;">Ctrl</a> <a href="/tags/DA/" style="font-size: 10px;">DA</a> <a href="/tags/DB/" style="font-size: 10.91px;">DB</a> <a href="/tags/DNN/" style="font-size: 10px;">DNN</a> <a href="/tags/DP/" style="font-size: 10px;">DP</a> <a href="/tags/Data-Augmentation/" style="font-size: 10px;">Data Augmentation</a> <a href="/tags/Data-Clearing/" style="font-size: 10px;">Data Clearing</a> <a href="/tags/Data-Enhancement/" style="font-size: 10px;">Data Enhancement</a> <a href="/tags/Data-Preprocess/" style="font-size: 10px;">Data Preprocess</a> <a href="/tags/Data-Science/" style="font-size: 14.55px;">Data Science</a> <a href="/tags/Data-Structure/" style="font-size: 16.36px;">Data Structure</a> <a href="/tags/Database/" style="font-size: 10px;">Database</a> <a href="/tags/DeBERTa/" style="font-size: 10px;">DeBERTa</a> <a href="/tags/Debiasing/" style="font-size: 10px;">Debiasing</a> <a href="/tags/Decoder/" style="font-size: 10px;">Decoder</a> <a href="/tags/Decoding/" style="font-size: 10px;">Decoding</a> <a href="/tags/Deep/" style="font-size: 10px;">Deep</a> <a href="/tags/DeepGraph/" style="font-size: 10px;">DeepGraph</a> <a href="/tags/DeepLearning/" style="font-size: 12.73px;">DeepLearning</a> <a href="/tags/Dependence/" style="font-size: 10px;">Dependence</a> <a href="/tags/Diary/" style="font-size: 10.91px;">Diary</a> <a href="/tags/Disentangled-Attention/" style="font-size: 10px;">Disentangled Attention</a> <a href="/tags/DistilBERT/" style="font-size: 10px;">DistilBERT</a> <a href="/tags/Distillation/" style="font-size: 10px;">Distillation</a> <a href="/tags/Django/" style="font-size: 10px;">Django</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Docker-Compose/" style="font-size: 10px;">Docker-Compose</a> <a href="/tags/Dockerfile/" style="font-size: 10px;">Dockerfile</a> <a href="/tags/Dropout/" style="font-size: 10.91px;">Dropout</a> <a href="/tags/Dynamic-Mask/" style="font-size: 10px;">Dynamic-Mask</a> <a href="/tags/EDA/" style="font-size: 10px;">EDA</a> <a href="/tags/EMD/" style="font-size: 10px;">EMD</a> <a href="/tags/ERNIE/" style="font-size: 10px;">ERNIE</a> <a href="/tags/Economics/" style="font-size: 10px;">Economics</a> <a href="/tags/Edit-Distance/" style="font-size: 10px;">Edit Distance</a> <a href="/tags/Efficient-DeepLearning/" style="font-size: 10px;">Efficient-DeepLearning</a> <a href="/tags/Elasticsearch/" style="font-size: 10px;">Elasticsearch</a> <a href="/tags/Electra/" style="font-size: 10px;">Electra</a> <a href="/tags/Elixir/" style="font-size: 10.91px;">Elixir</a> <a href="/tags/Ellipsis/" style="font-size: 10px;">Ellipsis</a> <a href="/tags/Embedding/" style="font-size: 11.82px;">Embedding</a> <a href="/tags/Embeddings/" style="font-size: 10.91px;">Embeddings</a> <a href="/tags/Encoder/" style="font-size: 10px;">Encoder</a> <a href="/tags/Entropy/" style="font-size: 10.91px;">Entropy</a> <a href="/tags/Evaluation/" style="font-size: 10.91px;">Evaluation</a> <a href="/tags/F1/" style="font-size: 10px;">F1</a> <a href="/tags/FDW/" style="font-size: 10px;">FDW</a> <a href="/tags/FSM/" style="font-size: 10px;">FSM</a> <a href="/tags/Feature-Engineering/" style="font-size: 10px;">Feature Engineering</a> <a href="/tags/Feature-based/" style="font-size: 10px;">Feature-based</a> <a href="/tags/Few-Shot/" style="font-size: 10px;">Few-Shot</a> <a href="/tags/Fine-tuning/" style="font-size: 10px;">Fine-tuning</a> <a href="/tags/Formal-Grammars/" style="font-size: 11.82px;">Formal Grammars</a> <a href="/tags/Forward/" style="font-size: 10px;">Forward</a> <a href="/tags/Full-Text-Search/" style="font-size: 10px;">Full-Text-Search</a> <a href="/tags/Function-Syntax/" style="font-size: 10px;">Function Syntax</a> <a href="/tags/Funk-MF/" style="font-size: 10px;">Funk MF</a> <a href="/tags/Funnel-Transformer/" style="font-size: 10px;">Funnel Transformer</a> <a href="/tags/GBTD/" style="font-size: 10px;">GBTD</a> <a href="/tags/GELU/" style="font-size: 10px;">GELU</a> <a href="/tags/GPT-2/" style="font-size: 10px;">GPT-2</a> <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/GRU/" style="font-size: 10px;">GRU</a> <a href="/tags/GSG/" style="font-size: 10px;">GSG</a> <a href="/tags/Gan/" style="font-size: 10px;">Gan</a> <a href="/tags/Garden-path/" style="font-size: 10px;">Garden-path</a> <a href="/tags/Git/" style="font-size: 10px;">Git</a> <a href="/tags/Glow/" style="font-size: 10px;">Glow</a> <a href="/tags/Graceful-Shutdown/" style="font-size: 10px;">Graceful Shutdown</a> <a href="/tags/Gradient-Descent/" style="font-size: 10px;">Gradient Descent</a> <a href="/tags/Graph/" style="font-size: 10.91px;">Graph</a> <a href="/tags/GraphQL/" style="font-size: 10.91px;">GraphQL</a> <a href="/tags/Grid-Grammar/" style="font-size: 10px;">Grid Grammar</a> <a href="/tags/HMM/" style="font-size: 10.91px;">HMM</a> <a href="/tags/Hard-SVM/" style="font-size: 10px;">Hard-SVM</a> <a href="/tags/Hinge-Loss/" style="font-size: 10px;">Hinge Loss</a> <a href="/tags/IE/" style="font-size: 10px;">IE</a> <a href="/tags/IQR/" style="font-size: 10px;">IQR</a> <a href="/tags/Imbalance-Data/" style="font-size: 10px;">Imbalance Data</a> <a href="/tags/Industry/" style="font-size: 10px;">Industry</a> <a href="/tags/Information-Extraction/" style="font-size: 10px;">Information Extraction</a> <a href="/tags/Information-Theory/" style="font-size: 10px;">Information Theory</a> <a href="/tags/Isolation-Forest/" style="font-size: 10px;">Isolation Forest</a> <a href="/tags/ItemCF/" style="font-size: 10px;">ItemCF</a> <a href="/tags/Jaccard/" style="font-size: 10px;">Jaccard</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/Jax/" style="font-size: 10px;">Jax</a> <a href="/tags/Job/" style="font-size: 10px;">Job</a> <a href="/tags/Jupyter/" style="font-size: 10px;">Jupyter</a> <a href="/tags/KKT/" style="font-size: 10px;">KKT</a> <a href="/tags/KS/" style="font-size: 10px;">KS</a> <a href="/tags/Kernel/" style="font-size: 10px;">Kernel</a> <a href="/tags/Kernel-Function/" style="font-size: 10px;">Kernel Function</a> <a href="/tags/Kernel-Method/" style="font-size: 10px;">Kernel Method</a> <a href="/tags/Keyword/" style="font-size: 10px;">Keyword</a> <a href="/tags/Knowledge-Graph/" style="font-size: 10.91px;">Knowledge Graph</a> <a href="/tags/LM/" style="font-size: 10.91px;">LM</a> <a href="/tags/LOF/" style="font-size: 10px;">LOF</a> <a href="/tags/LR/" style="font-size: 10px;">LR</a> <a href="/tags/LSTM/" style="font-size: 10px;">LSTM</a> <a href="/tags/Language-Model/" style="font-size: 10.91px;">Language Model</a> <a href="/tags/Lexical-Semantics/" style="font-size: 10px;">Lexical Semantics</a> <a href="/tags/Lexicalism/" style="font-size: 10px;">Lexicalism</a> <a href="/tags/Lexicalized-CFG/" style="font-size: 10px;">Lexicalized CFG</a> <a href="/tags/Lexicalized-Grammars/" style="font-size: 10px;">Lexicalized Grammars</a> <a href="/tags/Linear-Algebra/" style="font-size: 10px;">Linear Algebra</a> <a href="/tags/Linear-Sturcture/" style="font-size: 10px;">Linear Sturcture</a> <a href="/tags/Linked-List/" style="font-size: 10px;">Linked List</a> <a href="/tags/LinkedList/" style="font-size: 10.91px;">LinkedList</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a> <a href="/tags/Lucene/" style="font-size: 10px;">Lucene</a> <a href="/tags/Luong-Attention/" style="font-size: 10px;">Luong Attention</a> <a href="/tags/MEMM/" style="font-size: 10px;">MEMM</a> <a href="/tags/MF/" style="font-size: 10px;">MF</a> <a href="/tags/Machine/" style="font-size: 10px;">Machine</a> <a href="/tags/Machine-Learning/" style="font-size: 14.55px;">Machine Learning</a> <a href="/tags/Machine-Translation/" style="font-size: 10px;">Machine Translation</a> <a href="/tags/Manacher/" style="font-size: 10px;">Manacher</a> <a href="/tags/Managemnt/" style="font-size: 11.82px;">Managemnt</a> <a href="/tags/Markov/" style="font-size: 10px;">Markov</a> <a href="/tags/Materialized-Views/" style="font-size: 10px;">Materialized Views</a> <a href="/tags/Math/" style="font-size: 10.91px;">Math</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Matrix-Factorization/" style="font-size: 10px;">Matrix Factorization</a> <a href="/tags/Median/" style="font-size: 10px;">Median</a> <a href="/tags/Meta-Learning/" style="font-size: 10px;">Meta Learning</a> <a href="/tags/Metric/" style="font-size: 10px;">Metric</a> <a href="/tags/Minimum-Edit-Distance/" style="font-size: 10px;">Minimum Edit Distance</a> <a href="/tags/Minkowski/" style="font-size: 10px;">Minkowski</a> <a href="/tags/Model-Evaluation/" style="font-size: 10px;">Model Evaluation</a> <a href="/tags/Module/" style="font-size: 10px;">Module</a> <a href="/tags/Multi-Head-Attention/" style="font-size: 10px;">Multi-Head Attention</a> <a href="/tags/Multiway-Tree/" style="font-size: 10px;">Multiway Tree</a> <a href="/tags/NER/" style="font-size: 10.91px;">NER</a> <a href="/tags/NLG/" style="font-size: 10px;">NLG</a> <a href="/tags/NLM/" style="font-size: 10px;">NLM</a> <a href="/tags/NLP/" style="font-size: 20px;">NLP</a> <a href="/tags/NLU/" style="font-size: 10px;">NLU</a> <a href="/tags/NMT/" style="font-size: 10px;">NMT</a> <a href="/tags/Naive-Bayes/" style="font-size: 10px;">Naive Bayes</a> <a href="/tags/Neo4j/" style="font-size: 10px;">Neo4j</a> <a href="/tags/Ngram/" style="font-size: 10.91px;">Ngram</a> <a href="/tags/Normalizing-Flow/" style="font-size: 10px;">Normalizing Flow</a> <a href="/tags/NumPy/" style="font-size: 10px;">NumPy</a> <a href="/tags/Numba/" style="font-size: 10px;">Numba</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/Occupation/" style="font-size: 10px;">Occupation</a> <a href="/tags/Orientation/" style="font-size: 10px;">Orientation</a> <a href="/tags/P-R/" style="font-size: 10px;">P-R</a> <a href="/tags/PCCG/" style="font-size: 10px;">PCCG</a> <a href="/tags/PCFG/" style="font-size: 10px;">PCFG</a> <a href="/tags/PEGASUS/" style="font-size: 10px;">PEGASUS</a> <a href="/tags/PPMI/" style="font-size: 10px;">PPMI</a> <a href="/tags/PTM/" style="font-size: 10px;">PTM</a> <a href="/tags/PageRank/" style="font-size: 10px;">PageRank</a> <a href="/tags/Palindromic/" style="font-size: 10px;">Palindromic</a> <a href="/tags/Pandarallel/" style="font-size: 10px;">Pandarallel</a> <a href="/tags/Pandas/" style="font-size: 10.91px;">Pandas</a> <a href="/tags/Partial-Parsing/" style="font-size: 10px;">Partial Parsing</a> <a href="/tags/Pearson/" style="font-size: 10px;">Pearson</a> <a href="/tags/Philosophy/" style="font-size: 10.91px;">Philosophy</a> <a href="/tags/Phrase-Structure-Grammar/" style="font-size: 10px;">Phrase Structure Grammar</a> <a href="/tags/Phrase-Structure-Grammars/" style="font-size: 10px;">Phrase Structure Grammars</a> <a href="/tags/PoS/" style="font-size: 10px;">PoS</a> <a href="/tags/Polars/" style="font-size: 10px;">Polars</a> <a href="/tags/Pooling/" style="font-size: 10px;">Pooling</a> <a href="/tags/Position-Encoding/" style="font-size: 10px;">Position-Encoding</a> <a href="/tags/Postgres/" style="font-size: 10.91px;">Postgres</a> <a href="/tags/Pragmatic-Automatic-Processing/" style="font-size: 10px;">Pragmatic Automatic Processing</a> <a href="/tags/Pre-Trained/" style="font-size: 10px;">Pre-Trained</a> <a href="/tags/Pre-Training/" style="font-size: 10px;">Pre-Training</a> <a href="/tags/Pre-training/" style="font-size: 10.91px;">Pre-training</a> <a href="/tags/Precision/" style="font-size: 10px;">Precision</a> <a href="/tags/Pretrain/" style="font-size: 10px;">Pretrain</a> <a href="/tags/Pretrained/" style="font-size: 10px;">Pretrained</a> <a href="/tags/Pretraining/" style="font-size: 10.91px;">Pretraining</a> <a href="/tags/Probabilistic-Grammar/" style="font-size: 10px;">Probabilistic Grammar</a> <a href="/tags/Probabilistic-Model/" style="font-size: 10px;">Probabilistic Model</a> <a href="/tags/Prompt/" style="font-size: 10px;">Prompt</a> <a href="/tags/ProtoBERT/" style="font-size: 10px;">ProtoBERT</a> <a href="/tags/Pruning/" style="font-size: 10px;">Pruning</a> <a href="/tags/Psychology/" style="font-size: 10.91px;">Psychology</a> <a href="/tags/PyPI/" style="font-size: 10px;">PyPI</a> <a href="/tags/Python/" style="font-size: 18.18px;">Python</a> <a href="/tags/Quant/" style="font-size: 10px;">Quant</a> <a href="/tags/Quantization/" style="font-size: 10px;">Quantization</a> <a href="/tags/Query/" style="font-size: 10px;">Query</a> <a href="/tags/Queue/" style="font-size: 10px;">Queue</a> <a href="/tags/R-Drop/" style="font-size: 10.91px;">R-Drop</a> <a href="/tags/RELU/" style="font-size: 10px;">RELU</a> <a href="/tags/RFE/" style="font-size: 10px;">RFE</a> <a href="/tags/RMSE/" style="font-size: 10px;">RMSE</a> <a href="/tags/RNN/" style="font-size: 10px;">RNN</a> <a href="/tags/ROC/" style="font-size: 10px;">ROC</a> <a href="/tags/RaspberryPi/" style="font-size: 10.91px;">RaspberryPi</a> <a href="/tags/Raspberrypi/" style="font-size: 10px;">Raspberrypi</a> <a href="/tags/Recall/" style="font-size: 10px;">Recall</a> <a href="/tags/Recommendation/" style="font-size: 13.64px;">Recommendation</a> <a href="/tags/Recursion/" style="font-size: 10.91px;">Recursion</a> <a href="/tags/Reformer/" style="font-size: 10px;">Reformer</a> <a href="/tags/Regex/" style="font-size: 10px;">Regex</a> <a href="/tags/Regular-Expression/" style="font-size: 10px;">Regular Expression</a> <a href="/tags/Reinforcement-Learning/" style="font-size: 10px;">Reinforcement Learning</a> <a href="/tags/Relationship-Extraction/" style="font-size: 10px;">Relationship Extraction</a> <a href="/tags/Representation/" style="font-size: 10.91px;">Representation</a> <a href="/tags/Reqular-Expressions/" style="font-size: 10px;">Reqular Expressions</a> <a href="/tags/RoBERTa/" style="font-size: 10px;">RoBERTa</a> <a href="/tags/Rotated-Sorted-Array/" style="font-size: 10px;">Rotated Sorted Array</a> <a href="/tags/Rust/" style="font-size: 15.45px;">Rust</a> <a href="/tags/SCFG/" style="font-size: 10px;">SCFG</a> <a href="/tags/SGD/" style="font-size: 10px;">SGD</a> <a href="/tags/SMO/" style="font-size: 10px;">SMO</a> <a href="/tags/SQL/" style="font-size: 10.91px;">SQL</a> <a href="/tags/SRN/" style="font-size: 10px;">SRN</a> <a href="/tags/SVD/" style="font-size: 10px;">SVD++</a> <a href="/tags/SVM/" style="font-size: 10.91px;">SVM</a> <a href="/tags/Seaborn/" style="font-size: 10px;">Seaborn</a> <a href="/tags/Search/" style="font-size: 10.91px;">Search</a> <a href="/tags/Segmentation/" style="font-size: 10px;">Segmentation</a> <a href="/tags/Self-Attention/" style="font-size: 11.82px;">Self-Attention</a> <a href="/tags/Semantic-Automatic-Processing/" style="font-size: 10px;">Semantic Automatic Processing</a> <a href="/tags/Semantic-Similarity/" style="font-size: 10px;">Semantic Similarity</a> <a href="/tags/Senta/" style="font-size: 10px;">Senta</a> <a href="/tags/Sentence-Similarity/" style="font-size: 10px;">Sentence Similarity</a> <a href="/tags/Sentence-BERT/" style="font-size: 10px;">Sentence-BERT</a> <a href="/tags/Sentiment-Classification/" style="font-size: 10px;">Sentiment Classification</a> <a href="/tags/SentimentAnalysis/" style="font-size: 10px;">SentimentAnalysis</a> <a href="/tags/Siamese/" style="font-size: 10px;">Siamese</a> <a href="/tags/Sigmoid/" style="font-size: 10px;">Sigmoid</a> <a href="/tags/SimCSE/" style="font-size: 10.91px;">SimCSE</a> <a href="/tags/Similarity/" style="font-size: 10px;">Similarity</a> <a href="/tags/Simon/" style="font-size: 10px;">Simon</a> <a href="/tags/Simpson-Paradox/" style="font-size: 10px;">Simpson Paradox</a> <a href="/tags/Skill/" style="font-size: 10px;">Skill</a> <a href="/tags/Slide/" style="font-size: 10px;">Slide</a> <a href="/tags/Smoothing/" style="font-size: 10.91px;">Smoothing</a> <a href="/tags/Soft-SVM/" style="font-size: 10px;">Soft-SVM</a> <a href="/tags/Softmax/" style="font-size: 10px;">Softmax</a> <a href="/tags/Sort/" style="font-size: 10.91px;">Sort</a> <a href="/tags/Spell-Check/" style="font-size: 10px;">Spell Check</a> <a href="/tags/SqueezeBERT/" style="font-size: 10px;">SqueezeBERT</a> <a href="/tags/Stack/" style="font-size: 10px;">Stack</a> <a href="/tags/Stacking/" style="font-size: 10px;">Stacking</a> <a href="/tags/Statistics/" style="font-size: 10px;">Statistics</a> <a href="/tags/Stirling/" style="font-size: 10px;">Stirling</a> <a href="/tags/StratifiedKFold/" style="font-size: 10px;">StratifiedKFold</a> <a href="/tags/String/" style="font-size: 10.91px;">String</a> <a href="/tags/Style/" style="font-size: 10px;">Style</a> <a href="/tags/Substring/" style="font-size: 10px;">Substring</a> <a href="/tags/Summarization/" style="font-size: 10px;">Summarization</a> <a href="/tags/Supertagging/" style="font-size: 10px;">Supertagging</a> <a href="/tags/Swap/" style="font-size: 10px;">Swap</a> <a href="/tags/System/" style="font-size: 10.91px;">System</a> <a href="/tags/TF-IDF/" style="font-size: 10px;">TF-IDF</a> <a href="/tags/Tagging/" style="font-size: 10px;">Tagging</a> <a href="/tags/TanH/" style="font-size: 10px;">TanH</a> <a href="/tags/TensorBay/" style="font-size: 10px;">TensorBay</a> <a href="/tags/Tensorflow/" style="font-size: 10px;">Tensorflow</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Text-Classification/" style="font-size: 10px;">Text Classification</a> <a href="/tags/Text-Generation/" style="font-size: 10px;">Text Generation</a> <a href="/tags/Text-Normalization/" style="font-size: 10px;">Text Normalization</a> <a href="/tags/TextCNN/" style="font-size: 10.91px;">TextCNN</a> <a href="/tags/TextRank/" style="font-size: 10px;">TextRank</a> <a href="/tags/Thought/" style="font-size: 10px;">Thought</a> <a href="/tags/Transformer/" style="font-size: 17.27px;">Transformer</a> <a href="/tags/Transformer-XL/" style="font-size: 10px;">Transformer-XL</a> <a href="/tags/Tree/" style="font-size: 10px;">Tree</a> <a href="/tags/Treebank/" style="font-size: 10px;">Treebank</a> <a href="/tags/Tuning/" style="font-size: 10px;">Tuning</a> <a href="/tags/Tutorial/" style="font-size: 10px;">Tutorial</a> <a href="/tags/Ubuntu/" style="font-size: 10px;">Ubuntu</a> <a href="/tags/UniLM/" style="font-size: 10px;">UniLM</a> <a href="/tags/Unity-Operation/" style="font-size: 10px;">Unity Operation</a> <a href="/tags/Unix/" style="font-size: 10px;">Unix</a> <a href="/tags/UserCF/" style="font-size: 10px;">UserCF</a> <a href="/tags/Vagrant/" style="font-size: 10px;">Vagrant</a> <a href="/tags/Valence/" style="font-size: 10px;">Valence</a> <a href="/tags/Vector-Semantics/" style="font-size: 10px;">Vector Semantics</a> <a href="/tags/VirtualBox/" style="font-size: 10px;">VirtualBox</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/Viterbi/" style="font-size: 10.91px;">Viterbi</a> <a href="/tags/Vocabulary-Learning/" style="font-size: 10px;">Vocabulary Learning</a> <a href="/tags/Voting/" style="font-size: 10px;">Voting</a> <a href="/tags/WOE/" style="font-size: 10px;">WOE</a> <a href="/tags/Web-Server-Multithreaded-Server/" style="font-size: 10px;">Web Server Multithreaded Server</a> <a href="/tags/Wide/" style="font-size: 10px;">Wide</a> <a href="/tags/Word2vec/" style="font-size: 10px;">Word2vec</a> <a href="/tags/Work/" style="font-size: 10px;">Work</a> <a href="/tags/XLNet/" style="font-size: 10px;">XLNet</a> <a href="/tags/Z-Score/" style="font-size: 10px;">Z-Score</a> <a href="/tags/ZhouZhihua/" style="font-size: 10px;">ZhouZhihua</a> <a href="/tags/Zipf/" style="font-size: 10px;">Zipf</a> <a href="/tags/binning/" style="font-size: 10px;">binning</a> <a href="/tags/few-shot/" style="font-size: 10px;">few-shot</a> <a href="/tags/ffmpeg/" style="font-size: 10px;">ffmpeg</a> <a href="/tags/jpype/" style="font-size: 10px;">jpype</a> <a href="/tags/knowledge-Graph/" style="font-size: 10px;">knowledge Graph</a> <a href="/tags/motion/" style="font-size: 10px;">motion</a> <a href="/tags/node2vec/" style="font-size: 10px;">node2vec</a> <a href="/tags/ssh/" style="font-size: 10px;">ssh</a> <a href="/tags/str/" style="font-size: 10px;">str</a> <a href="/tags/vlc/" style="font-size: 10px;">vlc</a>
    </div>
  </aside>

  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2021/12/04/Paper/2021-12-04-Prompt/">Pretrain, Prompt and Predict, A Systematic Survey of Prompting Methods in NLP</a>
          </li>
        
          <li>
            <a href="/2021/11/28/Paper/2021-11-28-DataAugmentation/">Data Augmentation Approaches in Natural Language Processing：A Survey</a>
          </li>
        
          <li>
            <a href="/2021/11/18/Paper/2021-11-18-Debiasing/">Debiasing Techniques for Pre-Trained Language Models</a>
          </li>
        
          <li>
            <a href="/2021/11/13/Python/2021-11-13-Ellipsis/">Python Ellipsis</a>
          </li>
        
          <li>
            <a href="/2021/11/01/Paper/2021-11-01-MetaICL/">MetaICL：Learning to Learn In Context</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2021 Yam
    All rights reserved.</p>
    <p>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></p>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <!-- <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span> -->
    <!-- <span id="busuanzi_container_site_uv">本站访客数<span id="busuanzi_value_site_uv"></span>人次</span> -->

</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>